# -*- coding: utf-8 -*-
"""
è¾…åŠ©æ¨¡å‹å±•ç¤ºä¸åº”ç”¨é¡µé¢ - å®Œæ•´ç‰ˆï¼ˆåŒ…å«è™šæ‹Ÿç­›é€‰ï¼‰

å±•ç¤ºå·²è®­ç»ƒçš„è¾…åŠ©æ¨¡å‹ï¼Œæä¾›å•æˆåˆ†é¢„æµ‹ã€æ‰¹é‡ç‰¹å¾æ³¨å…¥å’Œè™šæ‹Ÿç­›é€‰åŠŸèƒ½

Author: HEAC Team  
Updated: 2025-12-18 - æ·»åŠ è™šæ‹Ÿç­›é€‰åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import joblib
import sys

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Import custom modules
try:
    from core.feature_injector import FeatureInjector
    from core.data_standardizer import standardize_dataframe, CompositionParser
    MODULES_AVAILABLE = True
except ImportError as e:
    MODULES_AVAILABLE = False
    import_error = str(e)

# Page config
st.set_page_config(
    page_title="è¾…åŠ©æ¨¡å‹ - HEAC",
    page_icon="ğŸ”¬",
    layout="wide"
)

# Title and description
st.title("ğŸ”¬ è¾…åŠ©æ¨¡å‹ (Proxy Models)")
st.markdown("""
åŸºäº84,000æ¡DFTç†è®ºæ•°æ®è®­ç»ƒçš„è¾…åŠ©æ¨¡å‹ï¼Œä¸ºHEAç²˜ç»“ç›¸é¢„æµ‹æ·±å±‚ç‰©ç†å±æ€§ã€‚
""")

# Check module availability
if not MODULES_AVAILABLE:
    st.error(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {import_error}")
    st.stop()

# Load models
@st.cache_resource
def load_models_and_metrics():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹å’Œæ€§èƒ½æŒ‡æ ‡"""
    model_dir = Path('models/proxy_models')
    
    if not model_dir.exists():
        return None, "æ¨¡å‹ç›®å½•ä¸å­˜åœ¨"
    
    try:
        models = {}
        metrics = {}
        
        # Load models
        model_files = {
            'formation_energy': 'formation_energy_model.pkl',
            'lattice': 'lattice_model.pkl',
            'magnetic_moment': 'magnetic_moment_model.pkl'
        }
        
        for name, filename in model_files.items():
            model_path = model_dir / filename
            if model_path.exists():
                models[name] = joblib.load(model_path)
        
        # Load metrics
        metric_files = {
            'formation_energy': 'formation_energy_metrics.pkl',
            'lattice': 'lattice_metrics.pkl',
            'magnetic_moment': 'magnetic_moment_metrics.pkl'
        }
        
        for name, filename in metric_files.items():
            metric_path = model_dir / filename
            if metric_path.exists():
                metrics[name] = joblib.load(metric_path)
        
        # Load feature names
        feature_path = model_dir / 'feature_names.pkl'
        if feature_path.exists():
            models['features'] = joblib.load(feature_path)
        
        return {'models': models, 'metrics': metrics}, None
        
    except Exception as e:
        return None, f"åŠ è½½å¤±è´¥: {str(e)}"

# Load models
data, error = load_models_and_metrics()

if error:
    st.error(error)
    st.info("è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼š`python scripts/train_model_a_formation.py`")
    st.stop()

models = data['models']
metrics = data['metrics']

# Sidebar navigation
page = st.sidebar.radio(
    "é€‰æ‹©åŠŸèƒ½",
    ["ğŸ“Š æ¨¡å‹æ¦‚è§ˆ", "ğŸ§ª å•æˆåˆ†é¢„æµ‹", "ğŸ“ æ‰¹é‡ç‰¹å¾æ³¨å…¥", "ğŸ”¬ è™šæ‹Ÿç­›é€‰", "ğŸ“ˆ æ€§èƒ½å¯è§†åŒ–"]
)

# ==========================================
# Page 1: Model Overview
# ==========================================
if page == "ğŸ“Š æ¨¡å‹æ¦‚è§ˆ":
    st.header("æ¨¡å‹æ€§èƒ½æ¦‚è§ˆ")
    
    # Performance metrics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'formation_energy' in metrics:
            m = metrics['formation_energy']
            st.metric(
                label="æ¨¡å‹A: å½¢æˆèƒ½",
                value=f"RÂ² = {m.get('r2', 0):.4f}",
                delta="â­ è¶…å‡ºé¢„æœŸ",
                help=f"MAE: {m.get('mae', 0):.4f} eV/atom"
            )
        else:
            st.metric(label="æ¨¡å‹A: å½¢æˆèƒ½", value="æœªè®­ç»ƒ")
    
    with col2:
        if 'lattice' in metrics:
            m = metrics['lattice']
            st.metric(
                label="æ¨¡å‹B: æ™¶æ ¼å¸¸æ•°",
                value=f"RÂ² = {m.get('r2', 0):.4f}",
                delta="âœ… ä¿®å¤æˆåŠŸ",
                help=f"MAE: {m.get('mae', 0):.4f} Ã…Â³"
            )
        else:
            st.metric(label="æ¨¡å‹B: æ™¶æ ¼å¸¸æ•°", value="æœªè®­ç»ƒ")
    
    with col3:
        if 'magnetic_moment' in metrics:
            m = metrics['magnetic_moment']
            st.metric(
                label="æ¨¡å‹C: ç£çŸ©",
                value=f"RÂ² = {m.get('r2', 0):.4f}",
                delta="âœ… å®Œæˆ",
                help=f"MAE: {m.get('mae', 0):.4f} Î¼B"
            )
        else:
            st.metric(label="æ¨¡å‹C: ç£çŸ©", value="æœªè®­ç»ƒ")
    
    # Detailed metrics table
    st.subheader("è¯¦ç»†æ€§èƒ½æŒ‡æ ‡")
    
    metrics_data = []
    for name, m in metrics.items():
        if isinstance(m, dict) and 'r2' in m:
            metrics_data.append({
                'æ¨¡å‹': name.replace('_', ' ').title(),
                'ç›®æ ‡': m.get('target_name', 'N/A'),
                'RÂ²': f"{m.get('r2', 0):.4f}",
                'MAE': f"{m.get('mae', 0):.4f}",
                'RMSE': f"{m.get('rmse', 0):.4f}" if 'rmse' in m else 'N/A',
                'æ ·æœ¬æ•°': m.get('n_samples', m.get('valid_samples', 'N/A'))
            })
    
    if metrics_data:
        df_metrics = pd.DataFrame(metrics_data)
        st.dataframe(df_metrics, use_container_width=True)
    
    # Model information
    st.subheader("æ¨¡å‹ä¿¡æ¯")
    
    st.info("""
    **è®­ç»ƒæ•°æ®**: Zenodo HEAæ•°æ®é›† (84,024æ ·æœ¬)  
    **ç‰¹å¾å·¥ç¨‹**: Matminerç‰¹å¾åŒ– (250ç»´)  
    **ç®—æ³•**: XGBoost Regressor with 5-fold Cross-Validation  
    **ç‰©ç†æ„ä¹‰**: åŸºäºDFTè®¡ç®—çš„ç†è®ºé¢„æµ‹ï¼Œç”¨äºå¢å¼ºå®éªŒæ•°æ®
    """)
    
    # ROM models
    st.subheader("ROMè¶‹åŠ¿å› å­æ¨¡å‹")
    st.markdown("""
    **æ¨¡å‹D/E**: åŸºäºæ··åˆè§„åˆ™(Rule of Mixtures)çš„è¶‹åŠ¿é¢„æµ‹
    - ä½¿ç”¨PyMatGenå…ƒç´ æ•°æ®åº“
    - æä¾›å¼¹æ€§æ¨¡é‡å’ŒPughæ¯”è¶‹åŠ¿
    - ç”¨äºç›¸å¯¹æ¯”è¾ƒï¼Œéç»å¯¹å€¼é¢„æµ‹
    """)

# ==========================================
# Page 2: Single Composition Prediction
# ==========================================
elif page == "ğŸ§ª å•æˆåˆ†é¢„æµ‹":
    st.header("å•æˆåˆ†ç‰©ç†å±æ€§é¢„æµ‹")
    
    st.markdown("""
    è¾“å…¥HEAæˆåˆ†ï¼Œå®æ—¶é¢„æµ‹4ä¸ªæ·±å±‚ç‰©ç†å±æ€§ã€‚æ”¯æŒå¤šç§æˆåˆ†æ ¼å¼ã€‚
    """)
    
    # Input
    col1, col2 = st.columns([3, 1])
    
    with col1:
        comp_input = st.text_input(
            "æˆåˆ†è¾“å…¥",
            value="AlCoCrFeNi",
            help="æ”¯æŒæ ¼å¼: AlCoCrFeNi, Al0.2Co0.2Cr0.2Fe0.2Ni0.2, Al10Co20Cr20Fe20Ni30"
        )
    
    with col2:
        predict_btn = st.button("ğŸ”® é¢„æµ‹", type="primary", use_container_width=True)
    
    # Example compositions
    st.markdown("**ç¤ºä¾‹æˆåˆ†**: ")
    examples = ["AlCoCrFeNi", "CoCrNi", "TiZrNbTa", "Co80Ni20"]
    cols = st.columns(len(examples))
    for i, ex in enumerate(examples):
        if cols[i].button(ex, key=f"ex_{i}"):
            comp_input = ex
            predict_btn = True
    
    if predict_btn and comp_input:
        with st.spinner("è®¡ç®—ä¸­..."):
            try:
                # Initialize injector
                injector = FeatureInjector(model_dir='models/proxy_models')
                
                # Parse composition
                composition = injector.composition_parser.parse(comp_input)
                
                if composition is None:
                    st.error("æˆåˆ†è§£æå¤±è´¥ï¼è¯·æ£€æŸ¥æ ¼å¼")
                else:
                    # Display parsed composition
                    st.success(f"âœ… æˆåˆ†è§£ææˆåŠŸ")
                    comp_str = ', '.join([f"{elem}: {frac:.3f}" for elem, frac in composition.items()])
                    st.code(comp_str, language=None)
                    
                    # Predict properties
                    st.subheader("é¢„æµ‹ç»“æœ")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    # Formation energy
                    try:
                        ef = injector.predict_formation_energy(composition)
                        if ef is not None:
                            col1.metric("å½¢æˆèƒ½", f"{ef:.4f} eV/atom")
                            if ef < -0.1:
                                col1.success("ç¨³å®šæ€§: ä¼˜ç§€")
                            elif ef < 0:
                                col1.info("ç¨³å®šæ€§: è‰¯å¥½")
                            else:
                                col1.warning("ç¨³å®šæ€§: è¾ƒå¼±")
                    except Exception as e:
                        col1.error(f"é¢„æµ‹å¤±è´¥: {e}")
                    
                    # Lattice parameter
                    try:
                        lattice = injector.predict_lattice_parameter(composition)
                        if lattice is not None:
                            # Convert volume to lattice (FCC assumption)
                            a_fcc = (4 * lattice) ** (1/3)
                            col2.metric("æ™¶æ ¼å¸¸æ•° (FCC)", f"{a_fcc:.3f} Ã…")
                            
                            # Lattice mismatch
                            mismatch = injector.calculate_lattice_mismatch(lattice)
                            col2.metric("æ™¶æ ¼å¤±é… vs WC", f"{mismatch:.2f} %")
                    except Exception as e:
                        col2.error(f"é¢„æµ‹å¤±è´¥: {e}")
                    
                    # Magnetic moment
                    try:
                        magmom = injector.predict_magnetic_moment(composition)
                        if magmom is not None:
                            col3.metric("ç£çŸ©", f"{magmom:.2f} Î¼B")
                            if magmom < 0.5:
                                col3.info("éç£æ€§/ä½ç£")
                            elif magmom < 2:
                                col3.info("ä¸­ç­‰ç£æ€§")
                            else:
                                col3.warning("é«˜ç£æ€§")
                    except Exception as e:
                        col3.error(f"é¢„æµ‹å¤±è´¥: {e}")
                    
                    # ROM predictions (if available)
                    st.subheader("å¼¹æ€§æ€§èƒ½è¶‹åŠ¿ (ROMæ–¹æ³•)")
                    st.info("åŸºäºæ··åˆè§„åˆ™çš„è¶‹åŠ¿é¢„æµ‹ï¼Œç”¨äºç›¸å¯¹æ¯”è¾ƒ")
                    
                    try:
                        elastic = injector.predict_elastic_moduli(composition)
                        
                        col1, col2, col3 = st.columns(3)
                        
                        if elastic.get('bulk'):
                            col1.metric("ä½“æ¨¡é‡ (è¶‹åŠ¿)", f"{elastic['bulk']:.0f} GPa")
                        
                        if elastic.get('shear'):
                            col2.metric("å‰ªåˆ‡æ¨¡é‡ (è¶‹åŠ¿)", f"{elastic['shear']:.0f} GPa")
                        
                        if elastic.get('bulk') and elastic.get('shear'):
                            pugh = elastic['bulk'] / elastic['shear']
                            nature = "éŸ§æ€§ (Ductile)" if pugh > 1.75 else "è„†æ€§ (Brittle)"
                            col3.metric("Pughæ¯”", f"{pugh:.2f}", delta=nature)
                            
                    except Exception as e:
                        st.warning(f"ROMé¢„æµ‹ä¸å¯ç”¨: {e}")
                    
            except Exception as e:
                st.error(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")
                st.exception(e)

# ==========================================
# Page 3: Batch Feature Injection
# ==========================================
elif page == "ğŸ“ æ‰¹é‡ç‰¹å¾æ³¨å…¥":
    st.header("æ‰¹é‡ç‰¹å¾æ³¨å…¥")
    
    st.markdown("""
    ä¸Šä¼ åŒ…å«HEAæˆåˆ†çš„CSVæ–‡ä»¶ï¼Œè‡ªåŠ¨æ·»åŠ 4ä¸ªåŸºäºDFTæ•°æ®çš„è¾…åŠ©ç‰©ç†ç‰¹å¾ã€‚
    
    **æ³¨å…¥ç‰¹å¾**ï¼š
    - å½¢æˆèƒ½ (Formation Energy)
    - æ™¶æ ¼å¸¸æ•° (Lattice Parameter)  
    - æ™¶æ ¼å¤±é… vs WC (Lattice Mismatch)
    - ç£çŸ© (Magnetic Moment)
    """)
    
    # File upload
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSVæ–‡ä»¶",
        type=['csv'],
        help="æ–‡ä»¶åº”åŒ…å«HEAæˆåˆ†åˆ—"
    )
    
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            
            st.success(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
            
            # Select composition column
            comp_col = st.selectbox(
                "é€‰æ‹©æˆåˆ†åˆ—",
                df.columns,
                help="åŒ…å«HEAæˆåˆ†çš„åˆ—ï¼ˆå¦‚: binder_compositionï¼‰"
            )
            
            # Preview
            st.subheader("æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10), use_container_width=True)
            
            # Inject features button
            if st.button("ğŸ’‰ æ³¨å…¥ç‰¹å¾", type="primary"):
                with st.spinner("å¤„ç†ä¸­...è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ"):
                    try:
                        # Standardize
                        df_std = standardize_dataframe(df, merge_duplicates=True)
                        
                        # æ ‡å‡†åŒ–åˆ—åï¼šå°†ç”¨æˆ·é€‰æ‹©çš„åˆ—åè½¬æ¢ä¸ºæ ‡å‡†åŒ–åçš„åˆ—å
                        from core.data_standardizer import data_standardizer
                        data_standardizer._build_reverse_mapping()
                        comp_col_lower = comp_col.lower().strip().replace(' ', '_')
                        std_comp_col = data_standardizer._REVERSE_MAPPING.get(comp_col_lower, comp_col)
                        
                        # æ£€æŸ¥æ ‡å‡†åŒ–åçš„åˆ—æ˜¯å¦å­˜åœ¨
                        if std_comp_col not in df_std.columns:
                            st.error(f"ç¼ºå°‘æ•°æ®: æ ‡å‡†åŒ–åçš„æˆåˆ†åˆ— '{std_comp_col}' ä¸å­˜åœ¨äºDataFrameä¸­")
                            st.info(f"å¯ç”¨çš„åˆ—: {', '.join(df_std.columns.tolist())}")
                            st.stop()
                        
                        # Inject
                        injector = FeatureInjector(model_dir='models/proxy_models')
                        df_enhanced = injector.inject_features(
                            df_std,
                            comp_col=std_comp_col,
                            verbose=False
                        )
                        
                        st.success("âœ… ç‰¹å¾æ³¨å…¥å®Œæˆï¼")
                        
                        # Show new features
                        new_cols = [col for col in df_enhanced.columns 
                                   if col.startswith('pred_') or col == 'lattice_mismatch_wc']
                        
                        st.info(f"æ–°å¢ {len(new_cols)} ä¸ªç‰¹å¾: {', '.join(new_cols)}")
                        
                        # Preview enhanced data
                        st.subheader("å¢å¼ºæ•°æ®é¢„è§ˆ")
                        display_cols = [std_comp_col] + new_cols
                        if all(col in df_enhanced.columns for col in display_cols):
                            st.dataframe(df_enhanced[display_cols].head(10), use_container_width=True)
                        
                        # Statistics
                        st.subheader("ç‰¹å¾ç»Ÿè®¡")
                        st.dataframe(df_enhanced[new_cols].describe(), use_container_width=True)
                        
                        # Download button
                        csv = df_enhanced.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½å¢å¼ºæ•°æ®",
                            data=csv,
                            file_name="hea_enhanced_with_proxy.csv",
                            mime="text/csv",
                            type="primary"
                        )
                        
                    except Exception as e:
                        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                        st.exception(e)
                        
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

# ==========================================
# Page 4: Virtual Screening
# ==========================================
elif page == "ğŸ”¬ è™šæ‹Ÿç­›é€‰":
    st.header("è™šæ‹Ÿé«˜é€šé‡ç­›é€‰")
    
    st.markdown("""
    ğŸ”¬ åŸºäºç‰©ç†çº¦æŸçš„å¤šçº§ç­›é€‰æ¼æ–—ï¼Œä»å¤§é‡è™šæ‹Ÿé…æ–¹ä¸­ç­›é€‰æœ€ä¼˜å€™é€‰
    
    **ä¸‰çº§ç­›é€‰ç­–ç•¥**ï¼š
    - ğŸ”´ **Level 1**: ç¨³å®šæ€§è¿‡æ»¤ï¼ˆæ·˜æ±°~80%ï¼‰
    - ğŸŸ¡ **Level 2**: ç•Œé¢åŒ¹é…ï¼ˆä¼˜é€‰éŸ§æ€§ï¼‰
    - ğŸŸ¢ **Level 3**: ç»¼åˆè¯„åˆ†ï¼ˆå¤šç›®æ ‡ä¼˜åŒ–ï¼‰
    """)
    
    # Parameters
    with st.expander("âš™ï¸ ç­›é€‰å‚æ•°é…ç½®", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            n_generate = st.slider(
                "è™šæ‹Ÿé…æ–¹æ•°é‡",
                min_value=1000,
                max_value=100000,
                value=10000,
                step=1000,
                help="ç”Ÿæˆçš„è™šæ‹Ÿé…æ–¹æ€»æ•°ï¼ˆå»ºè®®å…ˆç”¨å°æ•°é‡æµ‹è¯•ï¼‰"
            )
            
            ef_threshold = st.slider(
                "å½¢æˆèƒ½é˜ˆå€¼ (eV/atom)",
                min_value=-0.5,
                max_value=0.2,
                value=-0.05,
                step=0.01,
                help="< æ­¤å€¼è®¤ä¸ºç¨³å®š"
            )
        
        with col2:
            mismatch_threshold = st.slider(
                "æ™¶æ ¼å¤±é…é˜ˆå€¼",
                min_value=0.0,
                max_value=0.2,
                value=0.05,
                step=0.01,
                help="ç•Œé¢åŒ¹é…çš„å¯æ¥å—èŒƒå›´"
            )
            
            top_n = st.slider(
                "è¿”å›Top N",
                min_value=5,
                max_value=100,
                value=20,
                step=5
            )
    
    # Start button
    if st.button("ğŸš€ å¼€å§‹è™šæ‹Ÿç­›é€‰", type="primary", use_container_width=True):
        
        progress = st.progress(0, text="åˆå§‹åŒ–...")
        
        try:
            # Import functions
            from scripts.virtual_screening import generate_virtual_recipes
            from scripts.inject_physics import filter_by_stability, filter_by_interface
            
            # Step 1: Generate
            progress.progress(10, text=f"[1/5] ç”Ÿæˆ {n_generate:,} ä¸ªè™šæ‹Ÿé…æ–¹...")
            df_virtual = generate_virtual_recipes(n_samples=n_generate)
            st.success(f"âœ“ ç”Ÿæˆå®Œæˆ: {len(df_virtual):,} ä¸ªé…æ–¹")
            
            # Step 2: Inject
            progress.progress(30, text="[2/5] è°ƒç”¨è¾…åŠ©æ¨¡å‹é¢„æµ‹...")
            injector = FeatureInjector(model_dir='models/proxy_models')
            df_enhanced = injector.inject_features(
                df_virtual,
                comp_col='binder_composition',
                verbose=False
            )
            st.success("âœ“ ç‰¹å¾æ³¨å…¥å®Œæˆ")
            
            # Step 3: Filter 1
            progress.progress(50, text="[3/5] ç¨³å®šæ€§è¿‡æ»¤...")
            df_stable = filter_by_stability(df_enhanced, ef_threshold=ef_threshold)
            
            if len(df_stable) == 0:
                st.error("æ‰€æœ‰é…æ–¹éƒ½è¢«æ·˜æ±°ï¼è¯·æ”¾å®½é˜ˆå€¼")
                st.stop()
            
            st.info(f"ç¨³å®šæ€§: {len(df_virtual):,} â†’ {len(df_stable):,} ({len(df_stable)/len(df_virtual)*100:.1f}%)")
            
            # Step 4: Filter 2
            progress.progress(70, text="[4/5] ç•Œé¢åŒ¹é…è¿‡æ»¤...")
            df_matched = filter_by_interface(df_stable, mismatch_threshold=mismatch_threshold)
            
            if len(df_matched) == 0:
                st.warning("ç•Œé¢è¿‡æ»¤æ·˜æ±°æ‰€æœ‰é…æ–¹ï¼Œè¿”å›ç¨³å®šæ€§åˆæ ¼é…æ–¹")
                df_matched = df_stable
            
            st.info(f"ç•Œé¢: {len(df_stable):,} â†’ {len(df_matched):,} ({len(df_matched)/len(df_stable)*100:.1f}%)")
            
            # Step 5: Rank
            progress.progress(90, text="[5/5] ç»¼åˆè¯„åˆ†...")
            
            # Scoring
            df_matched['score'] = 0
            if 'pred_formation_energy' in df_matched.columns:
                df_matched['score'] += -df_matched['pred_formation_energy'] * 10
            if 'lattice_mismatch_wc' in df_matched.columns:
                df_matched['score'] += (1 - df_matched['lattice_mismatch_wc'].abs()) * 10
            if 'pred_pugh_ratio' in df_matched.columns:
                df_matched['score'] += (df_matched['pred_pugh_ratio'] - 1.75).clip(0, 1) * 5
            
            df_top = df_matched.sort_values('score', ascending=False).head(top_n)
            
            progress.progress(100, text="âœ… å®Œæˆï¼")
            
            # Results
            st.success(f"ğŸ¯ ç­›é€‰å®Œæˆï¼ä» {n_generate:,} â†’ Top {top_n}")
            
            # Display
            st.subheader(f"ğŸ† Top {top_n} å€™é€‰é…æ–¹")
            
            disp_cols = ['recipe_id', 'binder_composition', 
                        'pred_formation_energy', 'lattice_mismatch_wc', 'score']
            avail_cols = [c for c in disp_cols if c in df_top.columns]
            
            st.dataframe(df_top[avail_cols], use_container_width=True, height=400)
            
            # Download
            csv = df_top.to_csv(index=False).encode('utf-8')
            st.download_button(
                "ğŸ“¥ ä¸‹è½½å€™é€‰é…æ–¹",
                data=csv,
                file_name="virtual_screening_candidates.csv",
                mime="text/csv"
            )
            
        except Exception as e:
            st.error(f"ç­›é€‰å¤±è´¥: {str(e)}")
            st.exception(e)

# ==========================================
# Page 5: Performance Visualization
# ==========================================
elif page == "ğŸ“ˆ æ€§èƒ½å¯è§†åŒ–":
    st.header("æ¨¡å‹æ€§èƒ½å¯è§†åŒ–")
    
    st.info("æ­¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­")
    st.markdown("""
    è®¡åˆ’åŠŸèƒ½ï¼š
    - Parity Plot
    - è¯¯å·®åˆ†å¸ƒ
    - SHAPåˆ†æ
    """)
    
    if metrics:
        chart_data = pd.DataFrame([
            {'æ¨¡å‹': k.replace('_', ' ').title(), 'RÂ²': v.get('r2', 0)}
            for k, v in metrics.items()
            if isinstance(v, dict) and 'r2' in v
        ])
        
        if not chart_data.empty:
            st.bar_chart(chart_data.set_index('æ¨¡å‹'))

# Footer
st.markdown("---")
st.caption("ğŸ”¬ HEACé¡¹ç›® | è¾…åŠ©æ¨¡å‹ç³»ç»Ÿ v1.0")
