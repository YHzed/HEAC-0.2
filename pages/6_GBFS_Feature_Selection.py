import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from scipy.stats import spearmanr
from sklearn.feature_selection import RFECV
from sklearn.model_selection import cross_val_score
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(page_title="GBFS Feature Selection", page_icon="ğŸ¯", layout="wide")

st.title("ğŸ¯ GBFS Feature Selection Workflow")
st.markdown("""
**ä¸‰å±‚ç‰¹å¾ç­›é€‰ç­–ç•¥**ï¼š
1. åˆ†å±‚èšç±»ï¼ˆSpearmanç›¸å…³æ€§ï¼‰
2. ç›®æ ‡å¯¼å‘ç°‡å†…ä¼˜é€‰
3. RFECVè‡ªåŠ¨ä¼˜åŒ–
""")

# ====================
# 1. æ•°æ®åŠ è½½
# ====================
st.header("ğŸ“ Step 1: Load Processed Data")

file_path = st.text_input("CSVæ–‡ä»¶è·¯å¾„", value=r"d:\ML\HEAC 0.2\datasets\hea_processed.csv")

if st.button("Load Data") or 'df_original' in st.session_state:
    try:
        if 'df_original' not in st.session_state:
            df = pd.read_csv(file_path)
            st.session_state.df_original = df
        else:
            df = st.session_state.df_original
        
        st.success(f"âœ“ åŠ è½½äº† {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—æ•°æ®")
        st.dataframe(df.head())
        
        # è¯†åˆ«ç›®æ ‡å˜é‡
        target_candidates = ['HV, kgf/mm2', 'TRS, MPa', 'KIC, MPaÂ·m1/2']
        available_targets = [t for t in target_candidates if t in df.columns]
        st.info(f"å¯ç”¨ç›®æ ‡å˜é‡: {', '.join(available_targets)}")
        
    except Exception as e:
        st.error(f"åŠ è½½å¤±è´¥: {e}")

# ====================
# 2. ç”Ÿæˆå¤åˆç‰¹å¾
# ====================
st.header("ğŸ§¬ Step 2: Generate Composite Features")

st.markdown("""
**å¤åˆç‰¹å¾ç±»å‹**ï¼š
- **åŠ æƒå¹³å‡**ï¼šæ•´ä½“ææ–™æ€§è´¨ = Î£(å„ç›¸æ€§è´¨ Ã— ä½“ç§¯åˆ†æ•°)
- **å·®å¼‚ç‰¹å¾**ï¼šç•Œé¢åº”åŠ›ã€å¤±é… = |Ceramic - Binder|
- **æ¯”å€¼ç‰¹å¾**ï¼šç›¸å¯¹å…³ç³» = Ceramic / Binder
- **ç•Œé¢ç‰¹å¾**ï¼šç•Œé¢å¤æ‚åº¦ã€å¹³å‡è‡ªç”±ç¨‹
""")

def generate_composite_features(df):
    """ç”Ÿæˆç¡¬è´¨ç›¸-ç²˜ç»“ç›¸å¤åˆäº¤äº’ç‰¹å¾"""
    
    df_composite = df.copy()
    new_features = []
    
    # 1. ä½“ç§¯åˆ†æ•°åŠ æƒå¹³å‡ç‰¹å¾
    st.write("â³ ç”ŸæˆåŠ æƒå¹³å‡ç‰¹å¾...")
    
    # è¯†åˆ«MagpieDataç‰¹å¾
    magpie_features = []
    for col in df.columns:
        if 'Ceramic_MagpieData mean' in col:
            feature_name = col.replace('Ceramic_MagpieData mean ', '')
            binder_col = f'Binder_MagpieData mean {feature_name}'
            
            if binder_col in df.columns:
                magpie_features.append(feature_name)
    
    for feat in magpie_features:
        ceramic_col = f'Ceramic_MagpieData mean {feat}'
        binder_col = f'Binder_MagpieData mean {feat}'
        composite_col = f'Composite_MagpieData mean {feat}'
        
        if 'Ceramic_Vol_Frac' in df.columns and 'Binder_Vol_Frac' in df.columns:
            df_composite[composite_col] = (
                df[ceramic_col] * df['Ceramic_Vol_Frac'] +
                df[binder_col] * df['Binder_Vol_Frac']
            )
            new_features.append(composite_col)
    
    st.success(f"âœ“ ç”Ÿæˆäº† {len(magpie_features)} ä¸ªåŠ æƒå¹³å‡ç‰¹å¾")
    
    # 2. å·®å¼‚ç‰¹å¾
    st.write("â³ ç”Ÿæˆå·®å¼‚ç‰¹å¾...")
    
    key_diff_features = ['Electronegativity', 'AtomicRadius', 'MeltingT', 'ModulusBulk',
                         'Number', 'AtomicWeight', 'Density', 'FusionHeat']
    
    diff_count = 0
    for feat in key_diff_features:
        ceramic_col = f'Ceramic_MagpieData mean {feat}'
        binder_col = f'Binder_MagpieData mean {feat}'
        
        if ceramic_col in df.columns and binder_col in df.columns:
            diff_col = f'Diff_{feat}'
            df_composite[diff_col] = abs(df[ceramic_col] - df[binder_col])
            new_features.append(diff_col)
            diff_count += 1
    
    st.success(f"âœ“ ç”Ÿæˆäº† {diff_count} ä¸ªå·®å¼‚ç‰¹å¾")
    
    # 3. æ¯”å€¼ç‰¹å¾
    st.write("â³ ç”Ÿæˆæ¯”å€¼ç‰¹å¾...")
    
    key_ratio_features = ['ModulusBulk', 'Density', 'MeltingT', 'AtomicWeight']
    
    ratio_count = 0
    for feat in key_ratio_features:
        ceramic_col = f'Ceramic_MagpieData mean {feat}'
        binder_col = f'Binder_MagpieData mean {feat}'
        
        if ceramic_col in df.columns and binder_col in df.columns:
            ratio_col = f'Ratio_{feat}'
            df_composite[ratio_col] = df[ceramic_col] / (df[binder_col] + 1e-6)
            new_features.append(ratio_col)
            ratio_count += 1
    
    st.success(f"âœ“ ç”Ÿæˆäº† {ratio_count} ä¸ªæ¯”å€¼ç‰¹å¾")
    
    # 4. ç•Œé¢ç›¸å…³ç‰¹å¾
    st.write("â³ ç”Ÿæˆç•Œé¢ç‰¹å¾...")
    
    if 'Ceramic_Vol_Frac' in df.columns:
        # ç•Œé¢å¤æ‚åº¦ï¼ˆæœ€å¤§å€¼åœ¨50%æ—¶ï¼‰
        df_composite['Interface_Complexity'] = (
            df['Ceramic_Vol_Frac'] * (1 - df['Ceramic_Vol_Frac']) * 4
        )
        new_features.append('Interface_Complexity')
    
    if 'Grain_Size_um' in df.columns and 'Binder_Vol_Frac' in df.columns:
        # å¹³å‡è‡ªç”±ç¨‹
        df_composite['Mean_Free_Path'] = (
            df['Grain_Size_um'] * df['Binder_Vol_Frac'] / 
            (1 - df['Binder_Vol_Frac'] + 1e-6)
        )
        new_features.append('Mean_Free_Path')
    
    st.success(f"âœ“ ç”Ÿæˆäº†ç•Œé¢ç‰¹å¾")
    
    return df_composite, new_features

if 'df_original' in st.session_state:
    if st.button("ğŸš€ Generate Composite Features"):
        with st.spinner("ç”Ÿæˆå¤åˆç‰¹å¾ä¸­..."):
            df_with_composite, new_feats = generate_composite_features(st.session_state.df_original)
            st.session_state.df_composite = df_with_composite
            st.session_state.composite_features = new_feats
            
            st.success(f"âœ… æ€»å…±ç”Ÿæˆäº† {len(new_feats)} ä¸ªå¤åˆç‰¹å¾ï¼")
            
            # æ˜¾ç¤ºç‰¹å¾åˆ†ç±»
            with st.expander("ğŸ“Š æŸ¥çœ‹ç”Ÿæˆçš„å¤åˆç‰¹å¾"):
                composite_feats = [f for f in new_feats if f.startswith('Composite_')]
                diff_feats = [f for f in new_feats if f.startswith('Diff_')]
                ratio_feats = [f for f in new_feats if f.startswith('Ratio_')]
                interface_feats = [f for f in new_feats if f.startswith('Interface_') or f.startswith('Mean_')]
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("åŠ æƒå¹³å‡", len(composite_feats))
                with col2:
                    st.metric("å·®å¼‚ç‰¹å¾", len(diff_feats))
                with col3:
                    st.metric("æ¯”å€¼ç‰¹å¾", len(ratio_feats))
                with col4:
                    st.metric("ç•Œé¢ç‰¹å¾", len(interface_feats))

# ====================
# 3. æ•°æ®é¢„æ¸…æ´—
# ====================
st.header("ğŸ§¹ Step 3: Data Pre-cleaning")

if 'df_composite' in st.session_state:
    df_work = st.session_state.df_composite.copy()
    
    # é€‰æ‹©ç›®æ ‡å˜é‡
    target_candidates = ['HV, kgf/mm2', 'TRS, MPa', 'KIC, MPaÂ·m1/2']
    available_targets = [t for t in target_candidates if t in df_work.columns]
    
    selected_target = st.selectbox(
        "ğŸ¯ é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆTargetï¼‰ç”¨äºç‰¹å¾ä¼˜åŒ–",
        available_targets,
        help="ä¸åŒçš„Targetä¼šå¯¼è‡´ä¸åŒçš„ç‰¹å¾é€‰æ‹©ç»“æœ"
    )
    
    if st.button("æ‰§è¡Œé¢„æ¸…æ´—"):
        with st.spinner("æ¸…æ´—æ•°æ®ä¸­..."):
            # 1. å¤„ç†ç¼ºå¤±çš„ç›®æ ‡å€¼
            df_clean = df_work.copy()
            df_clean = df_clean.replace('-', np.nan)
            
            before_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[selected_target])
            after_count = len(df_clean)
            
            st.info(f"ç§»é™¤äº† {before_count - after_count} è¡Œç¼ºå¤±ç›®æ ‡å€¼çš„æ•°æ®")
            
            # 2. é€‰æ‹©æ•°å€¼ç‰¹å¾
            numeric_cols = df_clean.select_dtypes(include=['number']).columns
            
            # ç§»é™¤ç›®æ ‡å˜é‡
            feature_cols = [c for c in numeric_cols if c not in target_candidates]
            
            X = df_clean[feature_cols]
            y = df_clean[selected_target]
            
            # 3. ç§»é™¤å¸¸é‡ç‰¹å¾
            constant_cols = []
            for col in X.columns:
                if X[col].nunique() <= 1:
                    constant_cols.append(col)
            
            if constant_cols:
                st.warning(f"ç§»é™¤äº† {len(constant_cols)} ä¸ªå¸¸é‡ç‰¹å¾")
                X = X.drop(columns=constant_cols)
            
            # 4. å¤„ç†ç‰¹å¾ç¼ºå¤±å€¼å’Œç±»å‹è½¬æ¢
            # å¼ºåˆ¶è½¬æ¢æ‰€æœ‰åˆ—ä¸ºæ•°å€¼ç±»å‹ï¼Œé¿å…spearmanrç­‰å‡½æ•°å‡ºé”™
            for col in X.columns:
                X[col] = pd.to_numeric(X[col], errors='coerce')
            
            X = X.fillna(X.median())
            
            # ç¡®ä¿yä¹Ÿæ˜¯æ•°å€¼ç±»å‹
            y = pd.to_numeric(y, errors='coerce')
            y = y.fillna(y.median())
            
            st.session_state.X_clean = X
            st.session_state.y_clean = y
            st.session_state.selected_target = selected_target
            
            st.success(f"âœ… æ¸…æ´—å®Œæˆï¼æœ€ç»ˆç‰¹å¾çŸ©é˜µ: {X.shape[0]} è¡Œ Ã— {X.shape[1]} åˆ—")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                ceramic_feats = len([c for c in X.columns if c.startswith('Ceramic_')])
                st.metric("ç¡¬è´¨ç›¸ç‰¹å¾", ceramic_feats)
            with col2:
                binder_feats = len([c for c in X.columns if c.startswith('Binder_')])
                st.metric("ç²˜ç»“ç›¸ç‰¹å¾", binder_feats)
            with col3:
                composite_feats = len([c for c in X.columns if c.startswith('Composite_') or 
                                      c.startswith('Diff_') or c.startswith('Ratio_') or
                                      c.startswith('Interface_') or c.startswith('Mean_')])
                st.metric("å¤åˆç‰¹å¾", composite_feats)

# ====================
# 4. GBFSåˆ†å±‚èšç±»
# ====================
st.header("ğŸŒ³ Step 4: GBFS Hierarchical Clustering")

if 'X_clean' in st.session_state:
    st.markdown("""
    **ç®—æ³•æµç¨‹**ï¼š
    1. è®¡ç®—Spearmanç›¸å…³æ€§çŸ©é˜µ
    2. è½¬æ¢ä¸ºè·ç¦»çŸ©é˜µ: D = 1 - |Correlation|
    3. Ward's Linkageåˆ†å±‚èšç±»
    4. ç›®æ ‡å¯¼å‘ç°‡å†…ä¼˜é€‰ï¼ˆé€‰æ‹©ä¸Targetç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾ï¼‰
    """)
    
    threshold = st.slider(
        "èšç±»è·ç¦»é˜ˆå€¼ï¼ˆCutoffï¼‰",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.05,
        help="é˜ˆå€¼è¶Šä½ï¼Œèšç±»è¶Šç»†ï¼Œä¿ç•™ç‰¹å¾è¶Šå¤š"
    )
    
    if st.button("ğŸš€ æ‰§è¡ŒGBFSèšç±»"):
        X = st.session_state.X_clean
        y = st.session_state.y_clean
        
        with st.spinner("æ‰§è¡Œåˆ†å±‚èšç±»..."):
            # 1. è®¡ç®—Spearmanç›¸å…³æ€§çŸ©é˜µ
            st.write("â³ è®¡ç®—Spearmanç›¸å…³æ€§...")
            corr_matrix = X.corr(method='spearman').abs()
            
            # 2. è½¬æ¢ä¸ºè·ç¦»çŸ©é˜µ
            distance_matrix = 1 - corr_matrix
            
            # 3. åˆ†å±‚èšç±»
            st.write("â³ æ‰§è¡ŒWard's Linkageèšç±»...")
            from scipy.spatial.distance import squareform
            condensed_dist = squareform(distance_matrix)
            linkage_matrix = linkage(condensed_dist, method='ward')
            
            # 4. ç»˜åˆ¶æ ‘çŠ¶å›¾
            st.write("â³ ç»˜åˆ¶Dendrogram...")
            fig, ax = plt.subplots(figsize=(20, 8))
            dendrogram(
                linkage_matrix,
                labels=X.columns,
                leaf_rotation=90,
                leaf_font_size=8,
                ax=ax
            )
            ax.axhline(y=threshold, color='r', linestyle='--', linewidth=2, 
                      label=f'Cutoff={threshold}')
            ax.set_title('Feature Dendrogram (GBFS)', fontsize=16)
            ax.set_xlabel('Features', fontsize=12)
            ax.set_ylabel('Distance', fontsize=12)
            ax.legend()
            plt.tight_layout()
            st.pyplot(fig)
            
            # 5. æå–èšç±»ç°‡
            clusters = fcluster(linkage_matrix, threshold, criterion='distance')
            n_clusters = len(np.unique(clusters))
            
            st.success(f"âœ“ è¯†åˆ«å‡º {n_clusters} ä¸ªç‰¹å¾ç°‡")
            
            # 6. ç›®æ ‡å¯¼å‘ç°‡å†…ä¼˜é€‰
            st.write("â³ ç°‡å†…ä¼˜é€‰ï¼ˆé€‰æ‹©ä¸Targetç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾ï¼‰...")
            
            selected_features = []
            cluster_info = []
            
            for cluster_id in np.unique(clusters):
                cluster_features = X.columns[clusters == cluster_id].tolist()
                
                # è®¡ç®—æ¯ä¸ªç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³æ€§
                correlations = {}
                for feat in cluster_features:
                    corr, _ = spearmanr(X[feat], y)
                    correlations[feat] = abs(corr)
                
                # é€‰æ‹©ç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾
                best_feature = max(correlations, key=correlations.get)
                selected_features.append(best_feature)
                
                cluster_info.append({
                    'Cluster': cluster_id,
                    'Size': len(cluster_features),
                    'Selected_Feature': best_feature,
                    'Correlation_with_Target': correlations[best_feature],
                    'All_Features': ', '.join(cluster_features[:3]) + ('...' if len(cluster_features) > 3 else '')
                })
            
            st.session_state.selected_features_gbfs = selected_features
            st.session_state.cluster_info = pd.DataFrame(cluster_info)
            
            st.success(f"âœ… GBFSå®Œæˆï¼ä» {X.shape[1]} ä¸ªç‰¹å¾ä¸­é€‰å‡º {len(selected_features)} ä¸ªä»£è¡¨ç‰¹å¾")
            
            # æ˜¾ç¤ºèšç±»ä¿¡æ¯
            with st.expander("ğŸ“Š æŸ¥çœ‹èšç±»è¯¦æƒ…"):
                st.dataframe(st.session_state.cluster_info)

# ====================
# 5. RFECVè¿›ä¸€æ­¥ä¼˜åŒ–
# ====================
st.header("ğŸ¯ Step 5: RFECV Optimization")

if 'selected_features_gbfs' in st.session_state:
    st.markdown("""
    ä½¿ç”¨ **XGBoost + äº¤å‰éªŒè¯** è‡ªåŠ¨ç¡®å®šæœ€ä¼˜ç‰¹å¾æ•°é‡ã€‚
    """)
    
    cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", min_value=3, max_value=10, value=5)
    
    if st.button("ğŸš€ æ‰§è¡ŒRFECV"):
        X = st.session_state.X_clean
        y = st.session_state.y_clean
        selected_feats = st.session_state.selected_features_gbfs
        
        X_selected = X[selected_feats]
        
        with st.spinner("æ‰§è¡ŒRFECVï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."):
            # RFECV
            estimator = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42
            )
            
            rfecv = RFECV(
                estimator=estimator,
                step=1,
                cv=cv_folds,
                scoring='r2',
                n_jobs=-1
            )
            
            rfecv.fit(X_selected, y)
            
            optimal_features = X_selected.columns[rfecv.support_].tolist()
            
            st.session_state.optimal_features = optimal_features
            st.session_state.rfecv = rfecv
            
            st.success(f"âœ… RFECVå®Œæˆï¼æœ€ä¼˜ç‰¹å¾æ•°: {len(optimal_features)}")
            
            # ç»˜åˆ¶RFECVæ›²çº¿
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1),
                   rfecv.cv_results_['mean_test_score'],
                   marker='o')
            ax.axvline(x=rfecv.n_features_, color='r', linestyle='--',
                      label=f'Optimal: {rfecv.n_features_} features')
            ax.set_xlabel('Number of Features')
            ax.set_ylabel('Cross-Validation RÂ² Score')
            ax.set_title('RFECV Feature Selection')
            ax.legend()
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(fig)
            
            # æ˜¾ç¤ºæœ€ä¼˜ç‰¹å¾
            with st.expander("ğŸ“‹ æœ€ä¼˜ç‰¹å¾åˆ—è¡¨"):
                st.write(optimal_features)

# ====================
# 6. ä¿å­˜ç»“æœ
# ====================
st.header("ğŸ’¾ Step 6: Save Results")

if 'optimal_features' in st.session_state:
    output_path = st.text_input(
        "è¾“å‡ºæ–‡ä»¶è·¯å¾„",
        value=r"d:\ML\HEAC 0.2\datasets\hea_selected_features.csv"
    )
    
    if st.button("ğŸ’¾ ä¿å­˜ç²¾ç®€æ•°æ®é›†"):
        optimal_feats = st.session_state.optimal_features
        target = st.session_state.selected_target
        df_final = st.session_state.df_composite
        
        # åˆ›å»ºæœ€ç»ˆæ•°æ®é›†
        final_cols = optimal_feats + [target]
        df_output = df_final[final_cols].dropna(subset=[target])
        
        df_output.to_csv(output_path, index=False)
        
        st.success(f"âœ… å·²ä¿å­˜åˆ°: {output_path}")
        st.write(f"**æœ€ç»ˆç»´åº¦**: {df_output.shape[0]} è¡Œ Ã— {df_output.shape[1]} åˆ—")
        st.dataframe(df_output.head())
        
        # ç‰¹å¾é‡è¦æ€§ï¼ˆä½¿ç”¨æœ€ç»ˆæ¨¡å‹ï¼‰
        if st.checkbox("æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§"):
            X_final = df_output[optimal_feats]
            y_final = df_output[target]
            
            model = xgb.XGBRegressor(n_estimators=100, max_depth=5, random_state=42)
            model.fit(X_final, y_final)
            
            importance_df = pd.DataFrame({
                'Feature': optimal_feats,
                'Importance': model.feature_importances_
            }).sort_values('Importance', ascending=False)
            
            fig, ax = plt.subplots(figsize=(10, max(6, len(optimal_feats) * 0.3)))
            ax.barh(importance_df['Feature'], importance_df['Importance'])
            ax.set_xlabel('Feature Importance')
            ax.set_title(f'Feature Importance for {target}')
            plt.tight_layout()
            st.pyplot(fig)
            
            st.dataframe(importance_df)

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.header("ğŸ“Š Process Summary")
    
    if 'df_original' in st.session_state:
        st.metric("åŸå§‹ç‰¹å¾æ•°", st.session_state.df_original.shape[1])
    
    if 'composite_features' in st.session_state:
        st.metric("å¤åˆç‰¹å¾æ•°", len(st.session_state.composite_features))
    
    if 'X_clean' in st.session_state:
        st.metric("æ¸…æ´—åç‰¹å¾æ•°", st.session_state.X_clean.shape[1])
    
    if 'selected_features_gbfs' in st.session_state:
        st.metric("GBFSç­›é€‰å", len(st.session_state.selected_features_gbfs))
    
    if 'optimal_features' in st.session_state:
        st.metric("RFECVæœ€ä¼˜æ•°", len(st.session_state.optimal_features))
        
        reduction = (
            1 - len(st.session_state.optimal_features) / st.session_state.df_original.shape[1]
        ) * 100
        st.metric("ç‰¹å¾å‰Šå‡ç‡", f"{reduction:.1f}%")
