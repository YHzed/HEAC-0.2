import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from scipy.stats import spearmanr
from sklearn.feature_selection import RFECV
from sklearn.model_selection import cross_val_score
import xgboost as xgb
import warnings

warnings.filterwarnings('ignore')

st.set_page_config(page_title="GBFS Feature Selection", page_icon="ğŸ¯", layout="wide")

import ui.style_manager as style_manager
style_manager.apply_theme()

style_manager.ui_header("ğŸ¯ GBFS Feature Selection Workflow")
st.markdown("""
**ä¸‰å±‚ç‰¹å¾ç­›é€‰ç­–ç•¥**ï¼š
1. åˆ†å±‚èšç±»ï¼ˆSpearmanç›¸å…³æ€§ï¼‰
2. ç›®æ ‡å¯¼å‘ç°‡å†…ä¼˜é€‰
3. RFECVè‡ªåŠ¨ä¼˜åŒ–
""")

# ====================
# 1. æ•°æ®åŠ è½½
# ====================
st.header("ğŸ“ Step 1: Load Processed Data")

file_path = st.text_input("CSVæ–‡ä»¶è·¯å¾„", value=r"d:\ML\HEAC 0.2\datasets\hea_processed.csv")

if st.button("Load Data") or 'df_original' in st.session_state:
    try:
        if 'df_original' not in st.session_state:
            df = pd.read_csv(file_path)
            st.session_state.df_original = df
        else:
            df = st.session_state.df_original
        
        st.success(f"âœ“ åŠ è½½äº† {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—æ•°æ®")
        st.dataframe(df.head())
        
        # æ™ºèƒ½è¯†åˆ«ç›®æ ‡å˜é‡ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        target_mappings = {
            'Hardness': ['HV, kgf/mm2', 'HV_kgf_mm2', 'HV', 'Hardness'],
            'Strength': ['TRS, MPa', 'TRS_MPa', 'TRS', 'Strength'],
            'Toughness': ['KIC, MPaÂ·m1/2', 'KIC_MPa_m', 'KIC', 'Toughness']
        }
        
        available_targets = []
        for category, variants in target_mappings.items():
            for variant in variants:
                if variant in df.columns:
                    # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹
                    missing_pct = df[variant].isna().sum() / len(df) * 100
                    valid_count = df[variant].notna().sum()
                    
                    if missing_pct < 50 and valid_count >= 10:
                        available_targets.append(variant)
                        break
                    else:
                        st.warning(f"âš ï¸ è·³è¿‡ `{variant}`: ç¼ºå¤±ç‡ {missing_pct:.1f}% è¿‡é«˜")
        
        if available_targets:
            st.success(f"âœ“ æ‰¾åˆ° {len(available_targets)} ä¸ªå¯ç”¨ç›®æ ‡å˜é‡: {', '.join(available_targets)}")
        else:
            st.error("âš ï¸ æ— å¯ç”¨ç›®æ ‡å˜é‡ï¼")
        
    except Exception as e:
        st.error(f"åŠ è½½å¤±è´¥: {e}")

# ====================
# 2. ç”Ÿæˆå¤åˆç‰¹å¾
# ====================
st.header("ğŸ§¬ Step 2: Generate Composite Features")

st.markdown("""
**å¤åˆç‰¹å¾ç±»å‹**ï¼š
- **åŠ æƒå¹³å‡**ï¼šæ•´ä½“ææ–™æ€§è´¨ = Î£(å„ç›¸æ€§è´¨ Ã— ä½“ç§¯åˆ†æ•°)
- **å·®å¼‚ç‰¹å¾**ï¼šç•Œé¢åº”åŠ›ã€å¤±é… = |Ceramic - Binder|
- **æ¯”å€¼ç‰¹å¾**ï¼šç›¸å¯¹å…³ç³» = Ceramic / Binder
- **ç•Œé¢ç‰¹å¾**ï¼šç•Œé¢å¤æ‚åº¦ã€å¹³å‡è‡ªç”±ç¨‹
""")

def generate_composite_features(df):
    """ç”Ÿæˆç¡¬è´¨ç›¸-ç²˜ç»“ç›¸å¤åˆäº¤äº’ç‰¹å¾"""
    
    df_composite = df.copy()
    new_features = []
    
    # 1. ä½“ç§¯åˆ†æ•°åŠ æƒå¹³å‡ç‰¹å¾
    st.write("â³ ç”ŸæˆåŠ æƒå¹³å‡ç‰¹å¾...")
    
    # è¯†åˆ«MagpieDataç‰¹å¾
    magpie_features = []
    for col in df.columns:
        if 'Ceramic_MagpieData mean' in col:
            feature_name = col.replace('Ceramic_MagpieData mean ', '')
            binder_col = f'Binder_MagpieData mean {feature_name}'
            
            if binder_col in df.columns:
                magpie_features.append(feature_name)
    
    for feat in magpie_features:
        ceramic_col = f'Ceramic_MagpieData mean {feat}'
        binder_col = f'Binder_MagpieData mean {feat}'
        composite_col = f'Composite_MagpieData mean {feat}'
        
        if 'Ceramic_Vol_Frac' in df.columns and 'Binder_Vol_Frac' in df.columns:
            df_composite[composite_col] = (
                df[ceramic_col] * df['Ceramic_Vol_Frac'] +
                df[binder_col] * df['Binder_Vol_Frac']
            )
            new_features.append(composite_col)
    
    st.success(f"âœ“ ç”Ÿæˆäº† {len(magpie_features)} ä¸ªåŠ æƒå¹³å‡ç‰¹å¾")
    
    # 2. å·®å¼‚ç‰¹å¾
    st.write("â³ ç”Ÿæˆå·®å¼‚ç‰¹å¾...")
    
    key_diff_features = ['Electronegativity', 'AtomicRadius', 'MeltingT', 'ModulusBulk',
                         'Number', 'AtomicWeight', 'Density', 'FusionHeat']
    
    diff_count = 0
    for feat in key_diff_features:
        ceramic_col = f'Ceramic_MagpieData mean {feat}'
        binder_col = f'Binder_MagpieData mean {feat}'
        
        if ceramic_col in df.columns and binder_col in df.columns:
            diff_col = f'Diff_{feat}'
            df_composite[diff_col] = abs(df[ceramic_col] - df[binder_col])
            new_features.append(diff_col)
            diff_count += 1
    
    st.success(f"âœ“ ç”Ÿæˆäº† {diff_count} ä¸ªå·®å¼‚ç‰¹å¾")
    
    # 3. æ¯”å€¼ç‰¹å¾
    st.write("â³ ç”Ÿæˆæ¯”å€¼ç‰¹å¾...")
    
    key_ratio_features = ['ModulusBulk', 'Density', 'MeltingT', 'AtomicWeight']
    
    ratio_count = 0
    for feat in key_ratio_features:
        ceramic_col = f'Ceramic_MagpieData mean {feat}'
        binder_col = f'Binder_MagpieData mean {feat}'
        
        if ceramic_col in df.columns and binder_col in df.columns:
            ratio_col = f'Ratio_{feat}'
            df_composite[ratio_col] = df[ceramic_col] / (df[binder_col] + 1e-6)
            new_features.append(ratio_col)
            ratio_count += 1
    
    st.success(f"âœ“ ç”Ÿæˆäº† {ratio_count} ä¸ªæ¯”å€¼ç‰¹å¾")
    
    # 4. ç•Œé¢ç›¸å…³ç‰¹å¾
    st.write("â³ ç”Ÿæˆç•Œé¢ç‰¹å¾...")
    
    if 'Ceramic_Vol_Frac' in df.columns:
        # ç•Œé¢å¤æ‚åº¦ï¼ˆæœ€å¤§å€¼åœ¨50%æ—¶ï¼‰
        df_composite['Interface_Complexity'] = (
            df['Ceramic_Vol_Frac'] * (1 - df['Ceramic_Vol_Frac']) * 4
        )
        new_features.append('Interface_Complexity')
    
    if 'Grain_Size_um' in df.columns and 'Binder_Vol_Frac' in df.columns:
        # å¹³å‡è‡ªç”±ç¨‹
        df_composite['Mean_Free_Path'] = (
            df['Grain_Size_um'] * df['Binder_Vol_Frac'] / 
            (1 - df['Binder_Vol_Frac'] + 1e-6)
        )
        new_features.append('Mean_Free_Path')
    
    st.success(f"âœ“ ç”Ÿæˆäº†ç•Œé¢ç‰¹å¾")
    
    return df_composite, new_features

if 'df_original' in st.session_state:
    if st.button("ğŸš€ Generate Composite Features"):
        with st.spinner("ç”Ÿæˆå¤åˆç‰¹å¾ä¸­..."):
            df_with_composite, new_feats = generate_composite_features(st.session_state.df_original)
            st.session_state.df_composite = df_with_composite
            st.session_state.composite_features = new_feats
            
            st.success(f"âœ… æ€»å…±ç”Ÿæˆäº† {len(new_feats)} ä¸ªå¤åˆç‰¹å¾ï¼")
            
            # æ˜¾ç¤ºç‰¹å¾åˆ†ç±»
            with st.expander("ğŸ“Š æŸ¥çœ‹ç”Ÿæˆçš„å¤åˆç‰¹å¾"):
                composite_feats = [f for f in new_feats if f.startswith('Composite_')]
                diff_feats = [f for f in new_feats if f.startswith('Diff_')]
                ratio_feats = [f for f in new_feats if f.startswith('Ratio_')]
                interface_feats = [f for f in new_feats if f.startswith('Interface_') or f.startswith('Mean_')]
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("åŠ æƒå¹³å‡", len(composite_feats))
                with col2:
                    st.metric("å·®å¼‚ç‰¹å¾", len(diff_feats))
                with col3:
                    st.metric("æ¯”å€¼ç‰¹å¾", len(ratio_feats))
                with col4:
                    st.metric("ç•Œé¢ç‰¹å¾", len(interface_feats))

# ====================
# 3. æ•°æ®é¢„æ¸…æ´—
# ====================
st.header("ğŸ§¹ Step 3: Data Pre-cleaning")

if 'df_composite' in st.session_state:
    df_work = st.session_state.df_composite.copy()
    
    # æ™ºèƒ½è¯†åˆ«ç›®æ ‡å˜é‡
    target_mappings = {
        'Hardness': ['HV, kgf/mm2', 'HV_kgf_mm2', 'HV', 'Hardness'],
        'Strength': ['TRS, MPa', 'TRS_MPa', 'TRS', 'Strength'],
        'Toughness': ['KIC, MPaÂ·m1/2', 'KIC_MPa_m', 'KIC', 'Toughness']
    }
    
    available_targets = []
    for category, variants in target_mappings.items():
        for variant in variants:
            if variant in df_work.columns:
                missing_pct = df_work[variant].isna().sum() / len(df_work) * 100
                valid_count = df_work[variant].notna().sum()
                
                if missing_pct < 50 and valid_count >= 10:
                    available_targets.append(variant)
                    break
    
    if not available_targets:
        st.error("âš ï¸ æ— å¯ç”¨ç›®æ ‡å˜é‡ï¼è¯·å…ˆåŠ è½½æ•°æ®ã€‚")
        st.stop()
    
    selected_target = st.selectbox(
        "ğŸ¯ é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆTargetï¼‰ç”¨äºç‰¹å¾ä¼˜åŒ–",
        available_targets,
        help="ä¸åŒçš„Targetä¼šå¯¼è‡´ä¸åŒçš„ç‰¹å¾é€‰æ‹©ç»“æœ"
    )
    
    if st.button("æ‰§è¡Œé¢„æ¸…æ´—"):
        with st.spinner("æ¸…æ´—æ•°æ®ä¸­..."):
            # 1. å¤„ç†ç¼ºå¤±çš„ç›®æ ‡å€¼
            df_clean = df_work.copy()
            df_clean = df_clean.replace('-', np.nan)
            
            before_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[selected_target])
            after_count = len(df_clean)
            
            st.info(f"ç§»é™¤äº† {before_count - after_count} è¡Œç¼ºå¤±ç›®æ ‡å€¼çš„æ•°æ®")
            
            # 2. é€‰æ‹©æ•°å€¼ç‰¹å¾
            numeric_cols = df_clean.select_dtypes(include=['number']).columns
            
            # ç§»é™¤ç›®æ ‡å˜é‡
            feature_cols = [c for c in numeric_cols if c not in available_targets]
            
            X = df_clean[feature_cols]
            y = df_clean[selected_target]
            
            # 3. ç§»é™¤å¸¸é‡ç‰¹å¾
            constant_cols = []
            for col in X.columns:
                if X[col].nunique() <= 1:
                    constant_cols.append(col)
            
            if constant_cols:
                st.warning(f"ç§»é™¤äº† {len(constant_cols)} ä¸ªå¸¸é‡ç‰¹å¾")
                X = X.drop(columns=constant_cols)
            
            # 4. å¤„ç†ç‰¹å¾ç¼ºå¤±å€¼å’Œç±»å‹è½¬æ¢
            # å¼ºåˆ¶è½¬æ¢æ‰€æœ‰åˆ—ä¸ºæ•°å€¼ç±»å‹ï¼Œé¿å…spearmanrç­‰å‡½æ•°å‡ºé”™
            for col in X.columns:
                X[col] = pd.to_numeric(X[col], errors='coerce')
            
            X = X.fillna(X.median())
            
            # ç¡®ä¿yä¹Ÿæ˜¯æ•°å€¼ç±»å‹
            y = pd.to_numeric(y, errors='coerce')
            y = y.fillna(y.median())
            
            st.session_state.X_clean = X
            st.session_state.y_clean = y
            st.session_state.selected_target = selected_target
            
            st.success(f"âœ… æ¸…æ´—å®Œæˆï¼æœ€ç»ˆç‰¹å¾çŸ©é˜µ: {X.shape[0]} è¡Œ Ã— {X.shape[1]} åˆ—")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                ceramic_feats = len([c for c in X.columns if c.startswith('Ceramic_')])
                st.metric("ç¡¬è´¨ç›¸ç‰¹å¾", ceramic_feats)
            with col2:
                binder_feats = len([c for c in X.columns if c.startswith('Binder_')])
                st.metric("ç²˜ç»“ç›¸ç‰¹å¾", binder_feats)
            with col3:
                composite_feats = len([c for c in X.columns if c.startswith('Composite_') or 
                                      c.startswith('Diff_') or c.startswith('Ratio_') or
                                      c.startswith('Interface_') or c.startswith('Mean_')])
                st.metric("å¤åˆç‰¹å¾", composite_feats)

# ====================
# 4. GBFSåˆ†å±‚èšç±»
# ====================
st.header("ğŸŒ³ Step 4: GBFS Hierarchical Clustering")

if 'X_clean' in st.session_state:
    st.markdown("""
    **ç®—æ³•æµç¨‹**ï¼š
    1. è®¡ç®—Spearmanç›¸å…³æ€§çŸ©é˜µ
    2. è½¬æ¢ä¸ºè·ç¦»çŸ©é˜µ: D = 1 - |Correlation|
    3. Ward's Linkageåˆ†å±‚èšç±»
    4. ç›®æ ‡å¯¼å‘ç°‡å†…ä¼˜é€‰ï¼ˆé€‰æ‹©ä¸Targetç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾ï¼‰
    """)
    
    threshold = st.slider(
        "èšç±»è·ç¦»é˜ˆå€¼ï¼ˆCutoffï¼‰",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.05,
        help="é˜ˆå€¼è¶Šä½ï¼Œèšç±»è¶Šç»†ï¼Œä¿ç•™ç‰¹å¾è¶Šå¤š"
    )
    
    if st.button("ğŸš€ æ‰§è¡ŒGBFSèšç±»"):
        X = st.session_state.X_clean
        y = st.session_state.y_clean
        
        with st.spinner("æ‰§è¡Œåˆ†å±‚èšç±»..."):
            # å®šä¹‰å…³é”®ç‰©ç†ç‰¹å¾ï¼ˆå§‹ç»ˆä¿ç•™ï¼‰
            critical_physics_features = [
                'pred_formation_energy',
                'pred_lattice_param',
                'lattice_mismatch_wc',
                'pred_magnetic_moment'
            ]
            
            # è¯†åˆ«å®é™…å­˜åœ¨çš„å…³é”®ç‰©ç†ç‰¹å¾
            existing_critical_features = [f for f in critical_physics_features if f in X.columns]
            
            if existing_critical_features:
                st.info(f"ğŸ”’ ä¿æŠ¤å…³é”®ç‰©ç†ç‰¹å¾ï¼ˆä¸å‚ä¸èšç±»ï¼Œè‡ªåŠ¨ä¿ç•™ï¼‰: {', '.join(existing_critical_features)}")
            
            # ä»ç‰¹å¾é›†ä¸­æ’é™¤å…³é”®ç‰©ç†ç‰¹å¾ï¼Œåªå¯¹å…¶ä»–ç‰¹å¾è¿›è¡Œèšç±»
            X_for_clustering = X.drop(columns=existing_critical_features, errors='ignore')
            
            # 1. è®¡ç®—Spearmanç›¸å…³æ€§çŸ©é˜µ
            st.write(f"â³ è®¡ç®—Spearmanç›¸å…³æ€§ï¼ˆ{len(X_for_clustering.columns)} ä¸ªç‰¹å¾ï¼‰...")
            corr_matrix = X_for_clustering.corr(method='spearman').abs()
            
            # 2. è½¬æ¢ä¸ºè·ç¦»çŸ©é˜µ
            distance_matrix = 1 - corr_matrix
            
            # 3. åˆ†å±‚èšç±»
            st.write("â³ æ‰§è¡ŒWard's Linkageèšç±»...")
            from scipy.spatial.distance import squareform
            condensed_dist = squareform(distance_matrix)
            linkage_matrix = linkage(condensed_dist, method='ward')
            
            # 4. ç»˜åˆ¶æ ‘çŠ¶å›¾
            st.write("â³ ç»˜åˆ¶Dendrogram...")
            fig, ax = plt.subplots(figsize=(20, 8))
            dendrogram(
                linkage_matrix,
                labels=X_for_clustering.columns,
                leaf_rotation=90,
                leaf_font_size=8,
                ax=ax
            )
            ax.axhline(y=threshold, color='r', linestyle='--', linewidth=2, 
                      label=f'Cutoff={threshold}')
            ax.set_title('Feature Dendrogram (GBFS)', fontsize=16)
            ax.set_xlabel('Features', fontsize=12)
            ax.set_ylabel('Distance', fontsize=12)
            ax.legend()
            plt.tight_layout()
            st.pyplot(fig)
            
            # 5. æå–èšç±»ç°‡
            clusters = fcluster(linkage_matrix, threshold, criterion='distance')
            n_clusters = len(np.unique(clusters))
            
            st.success(f"âœ“ è¯†åˆ«å‡º {n_clusters} ä¸ªç‰¹å¾ç°‡")
            
            # 6. ç›®æ ‡å¯¼å‘ç°‡å†…ä¼˜é€‰
            st.write("â³ ç°‡å†…ä¼˜é€‰ï¼ˆé€‰æ‹©ä¸Targetç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾ï¼‰...")
            
            selected_features = []
            cluster_info = []
            
            for cluster_id in np.unique(clusters):
                cluster_features = X_for_clustering.columns[clusters == cluster_id].tolist()
                
                # è®¡ç®—æ¯ä¸ªç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³æ€§
                correlations = {}
                for feat in cluster_features:
                    corr, _ = spearmanr(X_for_clustering[feat], y)
                    correlations[feat] = abs(corr)
                
                # é€‰æ‹©ç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾
                best_feature = max(correlations, key=correlations.get)
                selected_features.append(best_feature)
                
                cluster_info.append({
                    'Cluster': cluster_id,
                    'Size': len(cluster_features),
                    'Selected_Feature': best_feature,
                    'Correlation_with_Target': correlations[best_feature],
                    'All_Features': ', '.join(cluster_features[:3]) + ('...' if len(cluster_features) > 3 else '')
                })
            
            # æ·»åŠ å…³é”®ç‰©ç†ç‰¹å¾åˆ°é€‰æ‹©åˆ—è¡¨
            selected_features.extend(existing_critical_features)
            
            st.session_state.selected_features_gbfs = selected_features
            st.session_state.critical_physics_features = existing_critical_features
            st.session_state.cluster_info = pd.DataFrame(cluster_info)
            
            st.success(f"""
            âœ… GBFSå®Œæˆï¼
            - èšç±»ç­›é€‰: {len(selected_features) - len(existing_critical_features)} ä¸ªç‰¹å¾
            - å…³é”®ç‰©ç†ç‰¹å¾: {len(existing_critical_features)} ä¸ªï¼ˆè‡ªåŠ¨ä¿ç•™ï¼‰
            - **æ€»è®¡: {len(selected_features)} ä¸ªç‰¹å¾**
            """)
            
            # æ˜¾ç¤ºèšç±»ä¿¡æ¯
            with st.expander("ğŸ“Š æŸ¥çœ‹èšç±»è¯¦æƒ…"):
                st.dataframe(st.session_state.cluster_info)
            
            # æ˜¾ç¤ºå…³é”®ç‰©ç†ç‰¹å¾
            if existing_critical_features:
                with st.expander("ğŸ”’ è‡ªåŠ¨ä¿ç•™çš„å…³é”®ç‰©ç†ç‰¹å¾"):
                    for feat in existing_critical_features:
                        st.write(f"- âœ¨ {feat}")

# ====================
# 5. RFECVè¿›ä¸€æ­¥ä¼˜åŒ–
# ====================
st.header("ğŸ¯ Step 5: RFECV Optimization")

if 'selected_features_gbfs' in st.session_state:
    st.markdown("""
    ä½¿ç”¨ **XGBoost + äº¤å‰éªŒè¯** è‡ªåŠ¨ç¡®å®šæœ€ä¼˜ç‰¹å¾æ•°é‡ã€‚
    """)
    
    cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", min_value=3, max_value=10, value=5)
    
    if st.button("ğŸš€ æ‰§è¡ŒRFECV"):
        X = st.session_state.X_clean
        y = st.session_state.y_clean
        selected_feats = st.session_state.selected_features_gbfs
        
        X_selected = X[selected_feats]
        
        with st.spinner("æ‰§è¡ŒRFECVï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."):
            # RFECV
            estimator = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42
            )
            
            rfecv = RFECV(
                estimator=estimator,
                step=1,
                cv=cv_folds,
                scoring='r2',
                n_jobs=-1
            )
            
            rfecv.fit(X_selected, y)
            
            optimal_features = X_selected.columns[rfecv.support_].tolist()
            
            st.session_state.optimal_features_rfecv = optimal_features
            st.session_state.rfecv = rfecv
            
            st.success(f"âœ… RFECVå®Œæˆï¼æœ€ä¼˜ç‰¹å¾æ•°: {len(optimal_features)}")
            
            # ç»˜åˆ¶RFECVæ›²çº¿
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1),
                   rfecv.cv_results_['mean_test_score'],
                   marker='o')
            ax.axvline(x=rfecv.n_features_, color='r', linestyle='--',
                      label=f'Optimal: {rfecv.n_features_} features')
            ax.set_xlabel('Number of Features')
            ax.set_ylabel('Cross-Validation RÂ² Score')
            ax.set_title('RFECV Feature Selection')
            ax.legend()
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(fig)
            
            # æ˜¾ç¤ºæœ€ä¼˜ç‰¹å¾
            with st.expander("ğŸ“‹ RFECVè‡ªåŠ¨é€‰æ‹©çš„ç‰¹å¾åˆ—è¡¨"):
                st.write(optimal_features)
    
    # æ‰‹åŠ¨è°ƒæ•´ç‰¹å¾é€‰æ‹©
    if 'optimal_features_rfecv' in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ”§ æ‰‹åŠ¨è°ƒæ•´ç‰¹å¾é€‰æ‹©")
        st.markdown("""
        **ç›®çš„**: åœ¨ RFECV è‡ªåŠ¨é€‰æ‹©çš„åŸºç¡€ä¸Šè¿›è¡Œè°ƒæ•´ï¼š
        - âœ… **ä¿ç•™/ç§»é™¤** RFECV è‡ªåŠ¨é€‰æ‹©çš„ç‰¹å¾
        - â• **æ·»åŠ ** é¢å¤–çš„å…³é”®ç‰©ç†ç‰¹å¾
        
        **æœ€ç»ˆç‰¹å¾åˆ—è¡¨** = (RFECV ç‰¹å¾ - ç§»é™¤çš„ç‰¹å¾) + æ‰‹åŠ¨æ·»åŠ çš„ç‰¹å¾
        """)
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„ç‰¹å¾
        all_features = st.session_state.selected_features_gbfs
        rfecv_features = st.session_state.optimal_features_rfecv
        
        # åˆå§‹åŒ–é€‰æ‹©çŠ¶æ€
        if 'rfecv_features_keep' not in st.session_state:
            st.session_state.rfecv_features_keep = rfecv_features.copy()
        if 'manual_added_features' not in st.session_state:
            st.session_state.manual_added_features = []
        
        # å¯ä¾›æ·»åŠ çš„ç‰¹å¾ = GBFSç­›é€‰åçš„ç‰¹å¾ - RFECVå·²é€‰ç‰¹å¾
        available_for_manual = [f for f in all_features if f not in rfecv_features]
        
        st.info(f"ğŸ“Š RFECV å·²é€‰æ‹© {len(rfecv_features)} ä¸ªç‰¹å¾ï¼Œè¿˜æœ‰ {len(available_for_manual)} ä¸ªç‰¹å¾å¯ä¾›æ‰‹åŠ¨æ·»åŠ ")
        
        # åˆ›å»ºä¸¤ä¸ªæ ‡ç­¾é¡µ
        tab1, tab2 = st.tabs(["âœ… RFECV è‡ªåŠ¨é€‰æ‹©çš„ç‰¹å¾", "â• æ‰‹åŠ¨æ·»åŠ é¢å¤–ç‰¹å¾"])
        
        # ========== Tab 1: RFECV è‡ªåŠ¨é€‰æ‹©çš„ç‰¹å¾ ==========
        with tab1:
            st.markdown("""
            ä»¥ä¸‹æ˜¯ RFECV è‡ªåŠ¨é€‰æ‹©çš„ç‰¹å¾ï¼Œ**é»˜è®¤å…¨éƒ¨ä¿ç•™**ã€‚  
            å¦‚æœæ‚¨è®¤ä¸ºæŸäº›ç‰¹å¾ä¸é‡è¦ï¼Œå¯ä»¥å–æ¶ˆå‹¾é€‰æ¥ç§»é™¤å®ƒä»¬ã€‚
            """)
            
            # æœç´¢æ¡† - RFECVç‰¹å¾
            search_rfecv = st.text_input(
                "ğŸ” æœç´¢ RFECV ç‰¹å¾",
                placeholder="è¾“å…¥å…³é”®è¯è¿‡æ»¤...",
                key="search_rfecv"
            )
            
            # åˆ†ç»„RFECVç‰¹å¾
            def group_features(features):
                groups = {
                    'ç¡¬è´¨ç›¸ç‰¹å¾ (Ceramic_)': [],
                    'ç²˜ç»“ç›¸ç‰¹å¾ (Binder_)': [],
                    'å¤åˆç‰¹å¾ (Composite_)': [],
                    'å·®å¼‚ç‰¹å¾ (Diff_)': [],
                    'æ¯”å€¼ç‰¹å¾ (Ratio_)': [],
                    'ç•Œé¢ç‰¹å¾ (Interface_/Mean_)': [],
                    'å·¥è‰ºå‚æ•°': []
                }
                
                for feat in features:
                    if feat.startswith('Ceramic_'):
                        groups['ç¡¬è´¨ç›¸ç‰¹å¾ (Ceramic_)'].append(feat)
                    elif feat.startswith('Binder_'):
                        groups['ç²˜ç»“ç›¸ç‰¹å¾ (Binder_)'].append(feat)
                    elif feat.startswith('Composite_'):
                        groups['å¤åˆç‰¹å¾ (Composite_)'].append(feat)
                    elif feat.startswith('Diff_'):
                        groups['å·®å¼‚ç‰¹å¾ (Diff_)'].append(feat)
                    elif feat.startswith('Ratio_'):
                        groups['æ¯”å€¼ç‰¹å¾ (Ratio_)'].append(feat)
                    elif feat.startswith('Interface_') or feat.startswith('Mean_'):
                        groups['ç•Œé¢ç‰¹å¾ (Interface_/Mean_)'].append(feat)
                    else:
                        groups['å·¥è‰ºå‚æ•°'].append(feat)
                
                return groups
            
            # åº”ç”¨æœç´¢è¿‡æ»¤ - RFECV
            filtered_rfecv = rfecv_features
            if search_rfecv:
                search_keywords = search_rfecv.lower().split()
                filtered_rfecv = [
                    f for f in rfecv_features
                    if any(keyword in f.lower() for keyword in search_keywords)
                ]
                st.caption(f"ğŸ” æ‰¾åˆ° {len(filtered_rfecv)} ä¸ªåŒ¹é…çš„ç‰¹å¾")
            
            # åˆ†ç»„æ˜¾ç¤ºRFECVç‰¹å¾
            rfecv_groups = group_features(filtered_rfecv)
            rfecv_selected = []
            
            for group_name, features in rfecv_groups.items():
                if features:
                    with st.expander(f"{group_name} ({len(features)} ä¸ªç‰¹å¾)", expanded=len(features) <= 10):
                        # å…¨é€‰æŒ‰é’®
                        col_a, col_b = st.columns([1, 4])
                        with col_a:
                            select_all_rfecv = st.checkbox(
                                "å…¨é€‰", 
                                key=f"select_all_rfecv_{group_name}",
                                value=True
                            )
                        
                        # æ˜¾ç¤ºç‰¹å¾å¤é€‰æ¡†
                        for feat in features:
                            default_checked = (
                                feat in st.session_state.rfecv_features_keep or 
                                select_all_rfecv
                            )
                            
                            is_selected = st.checkbox(
                                feat,
                                value=default_checked,
                                key=f"rfecv_{feat}"
                            )
                            
                            if is_selected:
                                rfecv_selected.append(feat)
            
            st.session_state.rfecv_features_keep = rfecv_selected
            removed_count = len(rfecv_features) - len(rfecv_selected)
            
            if removed_count > 0:
                st.warning(f"âš ï¸ å·²ç§»é™¤ {removed_count} ä¸ª RFECV é€‰æ‹©çš„ç‰¹å¾")
            st.markdown(f"**ä¿ç•™çš„ RFECV ç‰¹å¾: {len(rfecv_selected)} ä¸ª**")
        
        # ========== Tab 2: æ‰‹åŠ¨æ·»åŠ é¢å¤–ç‰¹å¾ ==========
        with tab2:
            if available_for_manual:
                st.markdown("""
                ä»¥ä¸‹ç‰¹å¾æ˜¯ RFECV **æœªé€‰æ‹©**çš„ï¼Œä½†æ‚¨å¯ä»¥æ ¹æ®é¢†åŸŸçŸ¥è¯†æ‰‹åŠ¨æ·»åŠ å®ƒä»¬ã€‚
                """)
                
                # æœç´¢æ¡† - æ‰‹åŠ¨æ·»åŠ 
                search_manual = st.text_input(
                    "ğŸ” æœç´¢å¯æ·»åŠ çš„ç‰¹å¾",
                    placeholder="ä¾‹å¦‚ï¼šMagpieData, Diff, Ratio, Interface...",
                    key="search_manual"
                )
                
                # åº”ç”¨æœç´¢è¿‡æ»¤ - æ‰‹åŠ¨æ·»åŠ 
                filtered_manual = available_for_manual
                if search_manual:
                    search_keywords = search_manual.lower().split()
                    filtered_manual = [
                        f for f in available_for_manual 
                        if any(keyword in f.lower() for keyword in search_keywords)
                    ]
                    st.caption(f"ğŸ” æ‰¾åˆ° {len(filtered_manual)} ä¸ªåŒ¹é…çš„ç‰¹å¾")
                
                # åˆ†ç»„æ˜¾ç¤ºå¯æ·»åŠ ç‰¹å¾
                manual_groups = group_features(filtered_manual)
                manual_selected = []
                
                for group_name, features in manual_groups.items():
                    if features:
                        with st.expander(f"{group_name} ({len(features)} ä¸ªç‰¹å¾)", expanded=len(features) <= 10):
                            # å…¨é€‰æŒ‰é’®
                            col_a, col_b = st.columns([1, 4])
                            with col_a:
                                select_all_manual = st.checkbox(
                                    "å…¨é€‰", 
                                    key=f"select_all_manual_{group_name}"
                                )
                            
                            # æ˜¾ç¤ºç‰¹å¾å¤é€‰æ¡†
                            for feat in features:
                                default_checked = (
                                    feat in st.session_state.manual_added_features or 
                                    select_all_manual
                                )
                                
                                is_selected = st.checkbox(
                                    feat,
                                    value=default_checked,
                                    key=f"manual_{feat}"
                                )
                                
                                if is_selected:
                                    manual_selected.append(feat)
                
                st.session_state.manual_added_features = manual_selected
                st.markdown(f"**æ‰‹åŠ¨æ·»åŠ çš„ç‰¹å¾: {len(manual_selected)} ä¸ª**")
            else:
                st.info("RFECV å·²ç»é€‰æ‹©äº†æ‰€æœ‰ GBFS ç­›é€‰åçš„ç‰¹å¾ï¼Œæ— å¯æ·»åŠ çš„ç‰¹å¾")
        
        # ========== ç¡®è®¤æŒ‰é’® ==========
        st.markdown("---")
        
        # è®¡ç®—æœ€ç»ˆç‰¹å¾åˆ—è¡¨
        rfecv_kept = st.session_state.rfecv_features_keep
        manual_added = st.session_state.manual_added_features
        final_features = list(set(rfecv_kept + manual_added))
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("RFECV åŸé€‰æ‹©", len(rfecv_features))
        with col2:
            removed = len(rfecv_features) - len(rfecv_kept)
            st.metric("ç§»é™¤ç‰¹å¾", removed, delta=f"-{removed}" if removed > 0 else "0")
        with col3:
            st.metric("æ‰‹åŠ¨æ·»åŠ ", len(manual_added), delta=f"+{len(manual_added)}" if len(manual_added) > 0 else "0")
        with col4:
            st.metric("æœ€ç»ˆç‰¹å¾æ€»æ•°", len(final_features))
        
        # ç¡®è®¤æŒ‰é’®
        col_btn1, col_btn2, col_btn3 = st.columns([2, 2, 3])
        with col_btn1:
            if st.button("âœ… ç¡®è®¤æœ€ç»ˆç‰¹å¾åˆ—è¡¨", type="primary"):
                st.session_state.optimal_features = final_features
                st.session_state.manual_selected_features = manual_added
                
                st.success(f"""
                âœ… **ç‰¹å¾è°ƒæ•´å®Œæˆï¼**
                - RFECV ä¿ç•™: {len(rfecv_kept)} ä¸ª
                - RFECV ç§»é™¤: {len(rfecv_features) - len(rfecv_kept)} ä¸ª
                - æ‰‹åŠ¨æ·»åŠ : {len(manual_added)} ä¸ª
                - **æœ€ç»ˆç‰¹å¾æ€»æ•°: {len(final_features)} ä¸ª**
                """)
                
                # æ˜¾ç¤ºæœ€ç»ˆç‰¹å¾åˆ—è¡¨
                with st.expander("ğŸ“‹ æœ€ç»ˆç‰¹å¾åˆ—è¡¨è¯¦æƒ…"):
                    if len(rfecv_features) - len(rfecv_kept) > 0:
                        st.markdown("**ğŸ—‘ï¸ å·²ç§»é™¤çš„ RFECV ç‰¹å¾:**")
                        removed_features = [f for f in rfecv_features if f not in rfecv_kept]
                        for feat in removed_features:
                            st.write(f"- ~~{feat}~~")
                        st.markdown("---")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**âœ… ä¿ç•™çš„ RFECV ç‰¹å¾:**")
                        for feat in rfecv_kept:
                            st.write(f"- {feat}")
                    
                    with col2:
                        if manual_added:
                            st.markdown("**âœ¨ æ‰‹åŠ¨æ·»åŠ çš„ç‰¹å¾:**")
                            for feat in manual_added:
                                st.write(f"- {feat}")
                        else:
                            st.info("æœªæ·»åŠ æ‰‹åŠ¨ç‰¹å¾")
        
        with col_btn2:
            if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰é€‰æ‹©"):
                st.session_state.rfecv_features_keep = rfecv_features.copy()
                st.session_state.manual_added_features = []
                st.rerun()

# ====================
# 6. ä¿å­˜ç»“æœ
# ====================
st.header("ğŸ’¾ Step 6: Save Results")

if 'optimal_features' in st.session_state:
    output_path = st.text_input(
        "è¾“å‡ºæ–‡ä»¶è·¯å¾„",
        value=r"d:\ML\HEAC 0.2\datasets\hea_selected_features.csv"
    )
    
    if st.button("ğŸ’¾ ä¿å­˜ç²¾ç®€æ•°æ®é›†"):
        optimal_feats = st.session_state.optimal_features
        target = st.session_state.selected_target
        df_final = st.session_state.df_composite
        
        # åˆ›å»ºæœ€ç»ˆæ•°æ®é›†
        final_cols = optimal_feats + [target]
        df_output = df_final[final_cols].dropna(subset=[target])
        
        df_output.to_csv(output_path, index=False)
        
        st.success(f"âœ… å·²ä¿å­˜åˆ°: {output_path}")
        st.write(f"**æœ€ç»ˆç»´åº¦**: {df_output.shape[0]} è¡Œ Ã— {df_output.shape[1]} åˆ—")
        st.dataframe(df_output.head())
        
        # ç‰¹å¾é‡è¦æ€§ï¼ˆä½¿ç”¨æœ€ç»ˆæ¨¡å‹ï¼‰
        if st.checkbox("æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§"):
            X_final = df_output[optimal_feats]
            y_final = df_output[target]
            
            model = xgb.XGBRegressor(n_estimators=100, max_depth=5, random_state=42)
            model.fit(X_final, y_final)
            
            importance_df = pd.DataFrame({
                'Feature': optimal_feats,
                'Importance': model.feature_importances_
            }).sort_values('Importance', ascending=False)
            
            fig, ax = plt.subplots(figsize=(10, max(6, len(optimal_feats) * 0.3)))
            ax.barh(importance_df['Feature'], importance_df['Importance'])
            ax.set_xlabel('Feature Importance')
            ax.set_title(f'Feature Importance for {target}')
            plt.tight_layout()
            st.pyplot(fig)
            
            st.dataframe(importance_df)

# ä¾§è¾¹æ ä¿¡æ¯
with st.sidebar:
    st.header("ğŸ“Š Process Summary")
    
    if 'df_original' in st.session_state:
        st.metric("åŸå§‹ç‰¹å¾æ•°", st.session_state.df_original.shape[1])
    
    if 'composite_features' in st.session_state:
        st.metric("å¤åˆç‰¹å¾æ•°", len(st.session_state.composite_features))
    
    if 'X_clean' in st.session_state:
        st.metric("æ¸…æ´—åç‰¹å¾æ•°", st.session_state.X_clean.shape[1])
    
    if 'selected_features_gbfs' in st.session_state:
        st.metric("GBFSç­›é€‰å", len(st.session_state.selected_features_gbfs))
    
    if 'optimal_features' in st.session_state:
        st.metric("RFECVæœ€ä¼˜æ•°", len(st.session_state.optimal_features))
        
        reduction = (
            1 - len(st.session_state.optimal_features) / st.session_state.df_original.shape[1]
        ) * 100
        st.metric("ç‰¹å¾å‰Šå‡ç‡", f"{reduction:.1f}%")
