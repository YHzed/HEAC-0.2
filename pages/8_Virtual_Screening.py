import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
from pathlib import Path

# ç¡®ä¿coreå¯è¢«å¯¼å…¥
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.virtual_screening import VirtualScreening, format_composition_string

st.set_page_config(page_title="Virtual Screening", page_icon="ğŸ”¬", layout="wide")

st.title("ğŸ”¬ Virtual High-Throughput Screening")
st.markdown("""
**å·¥ä½œæµç¨‹**ï¼š
1. é…ç½®ç­›é€‰å‚æ•°ï¼ˆæ ·æœ¬æ•°ã€å…ƒç´ èŒƒå›´ã€å·¥è‰ºèŒƒå›´ï¼‰
2. é€‰æ‹©è®­ç»ƒå¥½çš„æ¨¡å‹
3. ç”Ÿæˆè™šæ‹Ÿé…æ–¹ â†’ è®¡ç®—ç‰¹å¾ â†’ é¢„æµ‹æ€§èƒ½ â†’ ç­›é€‰Top N
4. åˆ†æå’Œå¯¼å‡ºç»“æœ

> ğŸ’¡ **æ ¸å¿ƒä»·å€¼**ï¼šæ— éœ€å®éªŒå³å¯æ¢ç´¢åºå¤§çš„ææ–™è®¾è®¡ç©ºé—´ï¼Œå‘ç°é«˜æ€§èƒ½å€™é€‰é…æ–¹
""")

# ===================
# ä¾§è¾¹æ ï¼šå‚æ•°é…ç½®
# ===================
with st.sidebar:
    st.header("âš™ï¸ ç­›é€‰å‚æ•°é…ç½®")
    
    # æ ·æœ¬æ•°é‡
    n_samples = st.number_input(
        "è™šæ‹Ÿæ ·æœ¬æ•°é‡",
        min_value=1000,
        max_value=100000,
        value=50000,
        step=1000,
        help="ç”Ÿæˆçš„è™šæ‹Ÿé…æ–¹æ•°é‡ï¼Œè¶Šå¤šè¶Šèƒ½è¦†ç›–è®¾è®¡ç©ºé—´"
    )
    
    st.divider()
    
    # ç²˜ç»“ç›¸å…ƒç´ é€‰æ‹©
    st.subheader("ç²˜ç»“ç›¸å…ƒç´ ")
    available_elements = ['Co', 'Cr', 'Fe', 'Ni', 'Mo', 'Ti', 'Al', 'V', 'Mn', 'W']
    
    selected_elements = st.multiselect(
        "é€‰æ‹©ç²˜ç»“ç›¸å…ƒç´ ",
        options=available_elements,
        default=['Co', 'Cr', 'Fe', 'Ni', 'Mo'],
        help="å…¸å‹HEAå…ƒç´ ï¼šCo-Cr-Fe-Ni-Mo"
    )
    
    st.divider()
    
    # ç¡¬è´¨ç›¸é€‰æ‹©
    st.subheader("ç¡¬è´¨ç›¸")
    ceramic_type = st.selectbox(
        "é€‰æ‹©ç¡¬è´¨ç›¸ç±»å‹",
        options=['WC', 'TiC', 'TaC', 'NbC', 'Cr3C2', 'VC'],
        index=0,
        help="ç¢³åŒ–ç‰©ç¡¬è´¨ç›¸"
    )
    
    st.divider()
    
    # å‚æ•°èŒƒå›´è®¾ç½®
    st.subheader("å·¥è‰ºå‚æ•°èŒƒå›´")
    
    col1, col2 = st.columns(2)
    with col1:
        temp_min = st.number_input("çƒ§ç»“æ¸©åº¦æœ€å°å€¼ (Â°C)", value=1300, step=10)
    with col2:
        temp_max = st.number_input("çƒ§ç»“æ¸©åº¦æœ€å¤§å€¼ (Â°C)", value=1600, step=10)
    
    col1, col2 = st.columns(2)
    with col1:
        grain_min = st.number_input("æ™¶ç²’å°ºå¯¸æœ€å°å€¼ (Î¼m)", value=0.5, step=0.1)
    with col2:
        grain_max = st.number_input("æ™¶ç²’å°ºå¯¸æœ€å¤§å€¼ (Î¼m)", value=3.0, step=0.1)
    
    col1, col2 = st.columns(2)
    with col1:
        binder_min = st.number_input("ç²˜ç»“ç›¸å«é‡æœ€å°å€¼ (wt%)", value=5.0, step=1.0)
    with col2:
        binder_max = st.number_input("ç²˜ç»“ç›¸å«é‡æœ€å¤§å€¼ (wt%)", value=30.0, step=1.0)
    
    param_ranges = {
        'sinter_temp': (temp_min, temp_max),
        'grain_size': (grain_min, grain_max),
        'binder_wt_pct': (binder_min, binder_max)
    }
    
    st.divider()
    
    # Top N è®¾ç½®
    n_top = st.slider(
        "ç­›é€‰ Top N é…æ–¹",
        min_value=5,
        max_value=50,
        value=10,
        help="è¿”å›é¢„æµ‹æ€§èƒ½æœ€é«˜çš„Nä¸ªé…æ–¹"
    )

# ===================
# ä¸»åŒºåŸŸï¼šæ¨¡å‹é€‰æ‹©
# ===================
st.header("ğŸ“‚ Step 1: é€‰æ‹©è®­ç»ƒå¥½çš„æ¨¡å‹")

models_dir = Path("models")
if not models_dir.exists():
    st.error(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
    st.stop()

# æ‰«ææ¨¡å‹æ–‡ä»¶
model_files = list(models_dir.glob("*.pkl"))

if not model_files:
    st.error(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼ˆ.pklï¼‰åœ¨ {models_dir} ç›®å½•ä¸­")
    st.info("ğŸ’¡ è¯·å…ˆåœ¨ 'Model Training' é¡µé¢è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹")
    st.stop()

# è¯»å–æ¨¡å‹ä¿¡æ¯
model_info = []
for model_file in model_files:
    try:
        import joblib
        model_pkg = joblib.load(model_file)
        model_info.append({
            'path': model_file,
            'name': model_file.stem,
            'target': model_pkg.get('target_name', 'Unknown'),
            'cv_score': model_pkg.get('cv_score', None),
            'n_features': len(model_pkg.get('feature_names', []))
        })
    except Exception as e:
        st.warning(f"æ— æ³•è¯»å–æ¨¡å‹ {model_file.name}: {e}")

if not model_info:
    st.error("æ— æ³•åŠ è½½ä»»ä½•æ¨¡å‹")
    st.stop()

# æ¨¡å‹ä¿¡æ¯è¡¨æ ¼
model_df = pd.DataFrame(model_info)
st.dataframe(model_df[['name', 'target', 'cv_score', 'n_features']], use_container_width=True)

# æ¨¡å‹é€‰æ‹©
selected_model_name = st.selectbox(
    "é€‰æ‹©æ¨¡å‹",
    options=[m['name'] for m in model_info],
    format_func=lambda x: f"{x} ({next(m['target'] for m in model_info if m['name'] == x)})"
)

selected_model_path = next(m['path'] for m in model_info if m['name'] == selected_model_name)

# ===================
# æ‰§è¡Œè™šæ‹Ÿç­›é€‰
# ===================
st.header("ğŸš€ Step 2: æ‰§è¡Œè™šæ‹Ÿç­›é€‰")

# å‚æ•°éªŒè¯
if len(selected_elements) == 0:
    st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç²˜ç»“ç›¸å…ƒç´ ")
    st.stop()

if temp_min >= temp_max or grain_min >= grain_max or binder_min >= binder_max:
    st.error("å‚æ•°èŒƒå›´è®¾ç½®é”™è¯¯ï¼šæœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼")
    st.stop()

# æ˜¾ç¤ºé…ç½®æ‘˜è¦
with st.expander("ğŸ“‹ æŸ¥çœ‹ç­›é€‰é…ç½®", expanded=False):
    st.json({
        "æ ·æœ¬æ•°é‡": n_samples,
        "ç²˜ç»“ç›¸å…ƒç´ ": selected_elements,
        "ç¡¬è´¨ç›¸ç±»å‹": ceramic_type,
        "çƒ§ç»“æ¸©åº¦èŒƒå›´ (Â°C)": param_ranges['sinter_temp'],
        "æ™¶ç²’å°ºå¯¸èŒƒå›´ (Î¼m)": param_ranges['grain_size'],
        "ç²˜ç»“ç›¸å«é‡èŒƒå›´ (wt%)": param_ranges['binder_wt_pct'],
        "è¿”å›Top": n_top
    })

if st.button("ğŸ”¬ å¼€å§‹è™šæ‹Ÿç­›é€‰", type="primary"):
    try:
        # åˆå§‹åŒ–è™šæ‹Ÿç­›é€‰å™¨
        with st.spinner("åŠ è½½æ¨¡å‹..."):
            screener = VirtualScreening(str(selected_model_path))
        
        st.success(f"âœ“ æ¨¡å‹å·²åŠ è½½: {screener.target_name}")
        
        # æ‰§è¡Œç­›é€‰
        with st.spinner(f"æ‰§è¡Œè™šæ‹Ÿç­›é€‰ï¼ˆ{n_samples:,} æ ·æœ¬ï¼‰..."):
            # æ•è·printè¾“å‡ºåˆ°Streamlit
            import io
            import contextlib
            
            output_buffer = io.StringIO()
            
            with contextlib.redirect_stdout(output_buffer):
                top_candidates, all_candidates = screener.run_screening(
                    n_samples=n_samples,
                    n_top=n_top,
                    param_ranges=param_ranges,
                    binder_elements=selected_elements,
                    ceramic_type=ceramic_type,
                    return_all=True
                )
            
            # æ˜¾ç¤ºè¾“å‡º
            with st.expander("ğŸ“ ç­›é€‰æ—¥å¿—"):
                st.text(output_buffer.getvalue())
        
        # ä¿å­˜åˆ°session_state
        st.session_state.top_candidates = top_candidates
        st.session_state.all_candidates = all_candidates
        st.session_state.screener = screener
        
        st.success(f"âœ… ç­›é€‰å®Œæˆï¼å‘ç° Top {n_top} é…æ–¹")
        
    except Exception as e:
        st.error(f"ç­›é€‰å¤±è´¥: {e}")
        import traceback
        with st.expander("æŸ¥çœ‹å®Œæ•´é”™è¯¯ä¿¡æ¯"):
            st.code(traceback.format_exc())

# ===================
# ç»“æœå±•ç¤º
# ===================
if 'top_candidates' in st.session_state:
    st.header(f"ğŸ“Š Step 3: Top {n_top} å€™é€‰é…æ–¹")
    
    top_df = st.session_state.top_candidates
    screener = st.session_state.screener
    
    # æ ¼å¼åŒ–æˆåˆ†å­—ç¬¦ä¸²
    top_df['Binder_Formula'] = top_df['Binder_Composition'].apply(format_composition_string)
    
    # æ˜¾ç¤ºè¡¨æ ¼
    display_cols = [
        'Ceramic_Type',
        'Binder_Formula',
        'Binder_Wt_Pct',
        'Ceramic_Wt_Pct',
        'Sinter_Temp_C',
        'Grain_Size_um',
        f'Predicted_{screener.target_name}'
    ]
    
    st.dataframe(
        top_df[display_cols].style.format({
            'Binder_Wt_Pct': '{:.2f}',
            'Ceramic_Wt_Pct': '{:.2f}',
            'Sinter_Temp_C': '{:.1f}',
            'Grain_Size_um': '{:.2f}',
            f'Predicted_{screener.target_name}': '{:.2f}'
        }),
        use_container_width=True
    )
    
    # è¯¦ç»†æˆåˆ†å±•ç¤º
    with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†ç²˜ç»“ç›¸æˆåˆ†"):
        for idx, row in top_df.iterrows():
            rank = idx + 1
            pred_value = row[f'Predicted_{screener.target_name}']
            
            st.markdown(f"**Rank {rank}** - é¢„æµ‹ {screener.target_name}: **{pred_value:.2f}**")
            
            comp_dict = row['Binder_Composition']
            comp_df = pd.DataFrame(list(comp_dict.items()), columns=['Element', 'Fraction'])
            comp_df['Fraction'] = comp_df['Fraction'].apply(lambda x: f"{x:.4f}")
            
            col1, col2 = st.columns([1, 2])
            with col1:
                st.dataframe(comp_df, hide_index=True)
            with col2:
                st.markdown(f"""
                - ç¡¬è´¨ç›¸: {row['Ceramic_Type']} ({row['Ceramic_Wt_Pct']:.2f} wt%)
                - ç²˜ç»“ç›¸: {row['Binder_Formula']} ({row['Binder_Wt_Pct']:.2f} wt%)
                - çƒ§ç»“æ¸©åº¦: {row['Sinter_Temp_C']:.1f} Â°C
                - æ™¶ç²’å°ºå¯¸: {row['Grain_Size_um']:.2f} Î¼m
                """)
            
            st.divider()
    
    # å¯è§†åŒ–
    st.header("ğŸ“ˆ Step 4: æ•°æ®å¯è§†åŒ–")
    
    tab1, tab2, tab3 = st.tabs(["ç¡¬åº¦åˆ†å¸ƒ", "å‚æ•°åˆ†æ", "æˆåˆ†ç©ºé—´"])
    
    with tab1:
        st.subheader("é¢„æµ‹ç¡¬åº¦åˆ†å¸ƒ")
        
        all_df = st.session_state.all_candidates
        
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # ç»˜åˆ¶å…¨éƒ¨æ ·æœ¬åˆ†å¸ƒ
        ax.hist(all_df[f'Predicted_{screener.target_name}'], 
                bins=50, alpha=0.6, label='All Candidates', color='skyblue', edgecolor='black')
        
        # æ ‡è®°Top N
        top_values = top_df[f'Predicted_{screener.target_name}']
        ax.axvline(top_values.min(), color='r', linestyle='--', linewidth=2, 
                   label=f'Top {n_top} Threshold')
        
        ax.set_xlabel(f'{screener.target_name}', fontsize=12)
        ax.set_ylabel('Frequency', fontsize=12)
        ax.set_title(f'Distribution of Predicted {screener.target_name}', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        st.pyplot(fig)
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å¹³å‡å€¼", f"{all_df[f'Predicted_{screener.target_name}'].mean():.2f}")
        with col2:
            st.metric("æ ‡å‡†å·®", f"{all_df[f'Predicted_{screener.target_name}'].std():.2f}")
        with col3:
            st.metric("æœ€å°å€¼", f"{all_df[f'Predicted_{screener.target_name}'].min():.2f}")
        with col4:
            st.metric("æœ€å¤§å€¼", f"{all_df[f'Predicted_{screener.target_name}'].max():.2f}")
    
    with tab2:
        st.subheader("Topé…æ–¹å‚æ•°åˆ†æ")
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # çƒ§ç»“æ¸©åº¦
        ax = axes[0, 0]
        ax.scatter(top_df['Sinter_Temp_C'], top_df[f'Predicted_{screener.target_name}'], 
                   s=100, alpha=0.6, c=range(len(top_df)), cmap='viridis')
        ax.set_xlabel('Sintering Temperature (Â°C)')
        ax.set_ylabel(f'Predicted {screener.target_name}')
        ax.set_title('Temperature vs Performance')
        ax.grid(True, alpha=0.3)
        
        # æ™¶ç²’å°ºå¯¸
        ax = axes[0, 1]
        ax.scatter(top_df['Grain_Size_um'], top_df[f'Predicted_{screener.target_name}'], 
                   s=100, alpha=0.6, c=range(len(top_df)), cmap='viridis')
        ax.set_xlabel('Grain Size (Î¼m)')
        ax.set_ylabel(f'Predicted {screener.target_name}')
        ax.set_title('Grain Size vs Performance')
        ax.grid(True, alpha=0.3)
        
        # ç²˜ç»“ç›¸å«é‡
        ax = axes[1, 0]
        ax.scatter(top_df['Binder_Wt_Pct'], top_df[f'Predicted_{screener.target_name}'], 
                   s=100, alpha=0.6, c=range(len(top_df)), cmap='viridis')
        ax.set_xlabel('Binder Content (wt%)')
        ax.set_ylabel(f'Predicted {screener.target_name}')
        ax.set_title('Binder Content vs Performance')
        ax.grid(True, alpha=0.3)
        
        # å‚æ•°åˆ†å¸ƒï¼ˆç®±çº¿å›¾ï¼‰
        ax = axes[1, 1]
        params = ['Sinter_Temp_C', 'Grain_Size_um', 'Binder_Wt_Pct']
        normalized_data = []
        for param in params:
            # å½’ä¸€åŒ–åˆ°0-1
            values = top_df[param].values
            norm_values = (values - values.min()) / (values.max() - values.min() + 1e-10)
            normalized_data.append(norm_values)
        
        ax.boxplot(normalized_data, labels=['Temp', 'Grain', 'Binder'])
        ax.set_ylabel('Normalized Value (0-1)')
        ax.set_title('Parameter Distributions (Top Candidates)')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)
    
    with tab3:
        st.subheader("ç²˜ç»“ç›¸æˆåˆ†ç©ºé—´")
        
        # æå–å…ƒç´ å«é‡
        element_data = {}
        for el in selected_elements:
            element_data[el] = top_df['Binder_Composition'].apply(lambda x: x.get(el, 0))
        
        comp_df = pd.DataFrame(element_data)
        comp_df['Predicted'] = top_df[f'Predicted_{screener.target_name}'].values
        
        # ç›¸å…³æ€§çƒ­å›¾
        fig, ax = plt.subplots(figsize=(10, 8))
        
        corr_matrix = comp_df.corr()
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
                    center=0, ax=ax, cbar_kws={'label': 'Correlation'})
        ax.set_title('Element Fraction Correlation Matrix (Top Candidates)')
        
        st.pyplot(fig)
        
        # å…ƒç´ å¹³å‡å«é‡
        st.markdown("#### å¹³å‡å…ƒç´ å«é‡ï¼ˆTopé…æ–¹ï¼‰")
        
        avg_composition = comp_df[selected_elements].mean()
        
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.bar(avg_composition.index, avg_composition.values, color='steelblue', alpha=0.7, edgecolor='black')
        ax.set_ylabel('Average Fraction')
        ax.set_xlabel('Element')
        ax.set_title(f'Average Binder Composition (Top {n_top})')
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(avg_composition.values):
            ax.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        st.pyplot(fig)
    
    # å¯¼å‡ºåŠŸèƒ½
    st.header("ğŸ’¾ Step 5: å¯¼å‡ºç»“æœ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # å¯¼å‡ºTop N
        csv_top = top_df[display_cols].to_csv(index=False)
        st.download_button(
            label=f"ğŸ“¥ ä¸‹è½½ Top {n_top} é…æ–¹ (CSV)",
            data=csv_top,
            file_name=f"virtual_screening_top{n_top}_{screener.target_name}.csv",
            mime="text/csv"
        )
    
    with col2:
        # å¯¼å‡ºå…¨éƒ¨å€™é€‰ï¼ˆå¯é€‰ï¼‰
        if st.checkbox("åŒ…å«å…¨éƒ¨å€™é€‰é…æ–¹"):
            csv_all = all_df.to_csv(index=False)
            st.download_button(
                label=f"ğŸ“¥ ä¸‹è½½å…¨éƒ¨ {len(all_df)} ä¸ªå€™é€‰ (CSV)",
                data=csv_all,
                file_name=f"virtual_screening_all_{screener.target_name}.csv",
                mime="text/csv"
            )

# ä¾§è¾¹æ ç»Ÿè®¡ä¿¡æ¯
if 'top_candidates' in st.session_state:
    with st.sidebar:
        st.divider()
        st.header("ğŸ“Š ç­›é€‰ç»“æœæ‘˜è¦")
        
        top_df = st.session_state.top_candidates
        all_df = st.session_state.all_candidates
        screener = st.session_state.screener
        
        st.metric("æ€»å€™é€‰æ•°", f"{len(all_df):,}")
        st.metric("Topé…æ–¹æ•°", len(top_df))
        st.metric(f"æœ€é«˜ {screener.target_name}", 
                  f"{top_df[f'Predicted_{screener.target_name}'].max():.2f}")
        
        improvement = (
            (top_df[f'Predicted_{screener.target_name}'].min() - 
             all_df[f'Predicted_{screener.target_name}'].mean()) / 
            all_df[f'Predicted_{screener.target_name}'].mean() * 100
        )
        st.metric("ç›¸å¯¹å¹³å‡å€¼æå‡", f"{improvement:.1f}%")
