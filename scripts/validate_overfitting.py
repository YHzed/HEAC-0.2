"""
æ¨¡å‹è¿‡æ‹ŸåˆéªŒè¯è„šæœ¬

æ£€æŸ¥é¡¹ç›®ï¼š
1. äº¤å‰éªŒè¯æ€§èƒ½ä¸€è‡´æ€§
2. è®­ç»ƒé›† vs æµ‹è¯•é›†æ€§èƒ½å·®å¼‚ 
3. å­¦ä¹ æ›²çº¿åˆ†æ
4. æ¨¡å‹å¤æ‚åº¦è¯„ä¼°
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_validate, learning_curve
from core.proxy_models import ProxyModelTrainer

print("=" * 80)
print("æ¨¡å‹è¿‡æ‹ŸåˆéªŒè¯")
print("=" * 80)

# åŠ è½½å·²è®­ç»ƒæ¨¡å‹å’ŒæŒ‡æ ‡
model_dir = Path("saved_models/proxy")
metrics_file = model_dir / "metrics.pkl"

if not metrics_file.exists():
    print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æŒ‡æ ‡æ–‡ä»¶")
    exit(1)

# è¯»å–æŒ‡æ ‡
with open(metrics_file, 'rb') as f:
    metrics = pickle.load(f)

print("\nğŸ“Š å·²ä¿å­˜çš„æ¨¡å‹æŒ‡æ ‡:")
print("-" * 80)
for model_name, model_metrics in metrics.items():
    print(f"\n{model_name}:")
    print(f"  MAE:  {model_metrics['mae']:.4f}")
    print(f"  RMSE: {model_metrics['rmse']:.4f}")
    print(f"  RÂ²:   {model_metrics['r2']:.4f}")
    if 'cv_scores' in model_metrics:
        cv_scores = model_metrics['cv_scores']
        print(f"  CV RÂ² (meanÂ±std): {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}")

# é‡æ–°åŠ è½½æ•°æ®è¿›è¡ŒéªŒè¯
print("\n" + "=" * 80)
print("é‡æ–°éªŒè¯ï¼ˆç‹¬ç«‹æµ‹è¯•é›†ï¼‰")
print("=" * 80)

trainer = ProxyModelTrainer(
    data_file="training data/zenodo/structure_featurized.dat_all.csv",
    cv_folds=5
)

# åŠ è½½æ•°æ®
trainer.load_data()
print(f"\nâœ“ æ•°æ®åŠ è½½: {trainer.df.shape}")

# å‡†å¤‡ç‰¹å¾
X, y_formation, y_lattice, y_magnetic, is_mag = trainer.prepare_features()
print(f"âœ“ ç‰¹å¾å‡†å¤‡: {X.shape}")

# æ£€æŸ¥1: äº¤å‰éªŒè¯ç¨³å®šæ€§
print("\n" + "=" * 80)
print("æ£€æŸ¥1: äº¤å‰éªŒè¯ç¨³å®šæ€§")
print("=" * 80)

from sklearn.model_selection import cross_val_score

models_to_test = {
    'formation_energy': (X, y_formation),
    'lattice': (X, y_lattice),
    'magnetic_moment': (X[is_mag], y_magnetic[is_mag])
}

cv_results = {}

for model_name, (X_data, y_data) in models_to_test.items():
    model_file = model_dir / f"{model_name}_model.pkl"
    
    if not model_file.exists():
        print(f"âš ï¸  è·³è¿‡ {model_name}: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        continue
    
    with open(model_file, 'rb') as f:
        model = pickle.load(f)
    
    print(f"\n{model_name}:")
    
    # 5-foldäº¤å‰éªŒè¯
    cv_scores = cross_val_score(model, X_data, y_data, cv=5, 
                                scoring='r2', n_jobs=-1)
    
    print(f"  5-Fold CV RÂ²: {cv_scores}")
    print(f"  Mean: {cv_scores.mean():.4f}")
    print(f"  Std:  {cv_scores.std():.4f}")
    
    # åˆ¤æ–­ç¨³å®šæ€§
    if cv_scores.std() < 0.05:
        print(f"  âœ… ç¨³å®šæ€§è‰¯å¥½ (std < 0.05)")
    elif cv_scores.std() < 0.10:
        print(f"  âš ï¸  ç¨³å®šæ€§ä¸€èˆ¬ (0.05 < std < 0.10)")
    else:
        print(f"  âŒ ç¨³å®šæ€§è¾ƒå·® (std > 0.10)")
    
    cv_results[model_name] = {
        'scores': cv_scores,
        'mean': cv_scores.mean(),
        'std': cv_scores.std()
    }

# æ£€æŸ¥2: è®­ç»ƒé›† vs æµ‹è¯•é›†æ€§èƒ½
print("\n" + "=" * 80)
print("æ£€æŸ¥2: è®­ç»ƒé›† vs æµ‹è¯•é›†æ€§èƒ½å·®å¼‚")
print("=" * 80)

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error

for model_name, (X_data, y_data) in models_to_test.items():
    model_file = model_dir / f"{model_name}_model.pkl"
    
    if not model_file.exists():
        continue
    
    with open(model_file, 'rb') as f:
        model = pickle.load(f)
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X_data, y_data, test_size=0.2, random_state=42
    )
    
    # è®­ç»ƒé›†æ€§èƒ½
    y_train_pred = model.predict(X_train)
    r2_train = r2_score(y_train, y_train_pred)
    mae_train = mean_absolute_error(y_train, y_train_pred)
    
    # æµ‹è¯•é›†æ€§èƒ½
    y_test_pred = model.predict(X_test)
    r2_test = r2_score(y_test, y_test_pred)
    mae_test = mean_absolute_error(y_test, y_test_pred)
    
    # è®¡ç®—å·®å¼‚
    r2_diff = r2_train - r2_test
    mae_diff = mae_test - mae_train
    
    print(f"\n{model_name}:")
    print(f"  è®­ç»ƒé›† RÂ²: {r2_train:.4f}, MAE: {mae_train:.4f}")
    print(f"  æµ‹è¯•é›† RÂ²: {r2_test:.4f}, MAE: {mae_test:.4f}")
    print(f"  å·®å¼‚:    Î”RÂ²={r2_diff:.4f}, Î”MAE={mae_diff:.4f}")
    
    # åˆ¤æ–­è¿‡æ‹Ÿåˆ
    if r2_diff < 0.03 and mae_diff < 0.01:
        print(f"  âœ… æ— è¿‡æ‹Ÿåˆè¿¹è±¡")
    elif r2_diff < 0.05:
        print(f"  âš ï¸  è½»å¾®è¿‡æ‹Ÿåˆ")
    else:
        print(f"  âŒ å¯èƒ½è¿‡æ‹Ÿåˆ (Î”RÂ² > 0.05)")

# æ£€æŸ¥3: å­¦ä¹ æ›²çº¿
print("\n" + "=" * 80)
print("æ£€æŸ¥3: å­¦ä¹ æ›²çº¿åˆ†æ")
print("=" * 80)

for model_name, (X_data, y_data) in models_to_test.items():
    model_file = model_dir / f"{model_name}_model.pkl"
    
    if not model_file.exists():
        continue
    
    with open(model_file, 'rb') as f:
        model = pickle.load(f)
    
    print(f"\n{model_name}:")
    print(f"  è®¡ç®—å­¦ä¹ æ›²çº¿...")
    
    # å­¦ä¹ æ›²çº¿ï¼ˆä½¿ç”¨è¾ƒå°‘çš„è®­ç»ƒè§„æ¨¡ä»¥åŠ å¿«é€Ÿåº¦ï¼‰
    train_sizes = np.linspace(0.1, 1.0, 5)
    
    train_sizes_abs, train_scores, test_scores = learning_curve(
        model, X_data, y_data,
        train_sizes=train_sizes,
        cv=3,
        scoring='r2',
        n_jobs=-1
    )
    
    train_mean = train_scores.mean(axis=1)
    test_mean = test_scores.mean(axis=1)
    
    print(f"  è®­ç»ƒè§„æ¨¡      è®­ç»ƒé›†RÂ²    æµ‹è¯•é›†RÂ²    å·®å¼‚")
    print(f"  " + "-" * 50)
    for size, tr, te in zip(train_sizes_abs, train_mean, test_mean):
        diff = tr - te
        status = "âœ…" if diff < 0.05 else "âš ï¸" if diff < 0.10 else "âŒ"
        print(f"  {size:8.0f}      {tr:.4f}      {te:.4f}     {diff:.4f} {status}")
    
    # åˆ¤æ–­æ”¶æ•›
    if test_mean[-1] - test_mean[-2] < 0.01:
        print(f"  âœ… æ¨¡å‹å·²æ”¶æ•›")
    else:
        print(f"  âš ï¸  å¯èƒ½éœ€è¦æ›´å¤šæ•°æ®")

# æ£€æŸ¥4: æ¨¡å‹å¤æ‚åº¦
print("\n" + "=" * 80)
print("æ£€æŸ¥4: æ¨¡å‹å¤æ‚åº¦è¯„ä¼°")
print("=" * 80)

for model_name in ['formation_energy', 'lattice', 'magnetic_moment']:
    model_file = model_dir / f"{model_name}_model.pkl"
    
    if not model_file.exists():
        continue
    
    with open(model_file, 'rb') as f:
        model = pickle.load(f)
    
    # XGBoostå‚æ•°
    if hasattr(model, 'named_steps') and 'regressor' in model.named_steps:
        xgb = model.named_steps['regressor']
        
        print(f"\n{model_name}:")
        print(f"  n_estimators: {xgb.n_estimators}")
        print(f"  max_depth: {xgb.max_depth}")
        print(f"  learning_rate: {xgb.learning_rate}")
        print(f"  reg_lambda: {xgb.reg_lambda}")
        print(f"  reg_alpha: {xgb.reg_alpha}")
        
        # åˆ¤æ–­å¤æ‚åº¦
        if xgb.max_depth <= 10 and xgb.reg_lambda >= 0.01:
            print(f"  âœ… æ­£åˆ™åŒ–é€‚å½“")
        else:
            print(f"  âš ï¸  å¯èƒ½è¿‡äºå¤æ‚")

# æ€»ç»“
print("\n" + "=" * 80)
print("è¿‡æ‹ŸåˆéªŒè¯æ€»ç»“")
print("=" * 80)

print("\nâœ… éªŒè¯å®Œæˆï¼è¯·æŸ¥çœ‹ä¸Šè¿°å„é¡¹æ£€æŸ¥ç»“æœã€‚")
print("\nåˆ¤æ–­æ ‡å‡†:")
print("  â€¢ CVæ ‡å‡†å·® < 0.05: ç¨³å®šæ€§è‰¯å¥½")
print("  â€¢ Î”RÂ² < 0.03: æ— è¿‡æ‹Ÿåˆ")
print("  â€¢ Î”RÂ² < 0.05: è½»å¾®è¿‡æ‹Ÿåˆ")
print("  â€¢ Î”RÂ² > 0.05: å¯èƒ½è¿‡æ‹Ÿåˆ")
