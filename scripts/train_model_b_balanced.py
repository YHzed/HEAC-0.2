"""
å¹³è¡¡ç‰ˆæ¨¡å‹Bè®­ç»ƒè„šæœ¬ - æ™¶æ ¼å¸¸æ•°é¢„æµ‹å™¨

ä½¿ç”¨å¹³è¡¡çš„å‚æ•°ä»¥ç¡®ä¿è®­ç»ƒæˆåŠŸå®Œæˆ

ä½œè€…: HEACé¡¹ç›®ç»„
"""

import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ä½¿ç”¨æ ‡å‡†çš„proxy_modelsï¼Œä½†åœ¨è®­ç»ƒæ—¶è¦†ç›–å‚æ•°
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb
import pandas as pd
import numpy as np
import joblib

def main():
    print("=" * 80)
    print("ğŸ¯ è®­ç»ƒæ¨¡å‹Bï¼ˆå¹³è¡¡ç‰ˆï¼‰: æ™¶æ ¼å¸¸æ•°é¢„æµ‹å™¨")
    print("=" * 80)
    print("\nå¹³è¡¡ç­–ç•¥ï¼ˆé¿å…hangï¼‰:")
    print("  - n_estimators: 600 (é€‚ä¸­)")
    print("  - max_depth: 8 (æ§åˆ¶å¤æ‚åº¦)")
    print("  - learning_rate: 0.1 (å¹³è¡¡)")
    print("  - early_stopping: 50è½®")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½Zenodoæ•°æ®é›†...")
    data_path = 'training data/zenodo/structure_featurized.dat_all.csv'
    df = pd.read_csv(data_path, index_col=0)
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
    
    # å‡†å¤‡ç‰¹å¾
    print("\nğŸ”§ å‡†å¤‡ç‰¹å¾çŸ©é˜µ...")
    nfeatures = 273
    feature_names = df.columns[-nfeatures:]
    X_all = df[feature_names]
    
    # ç§»é™¤é›¶æ–¹å·®ç‰¹å¾
    variance = X_all.var()
    valid_features = variance[variance != 0].index
    X = X_all[valid_features]
    print(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆ: {len(valid_features)} ä¸ªæœ‰æ•ˆç‰¹å¾")
    
    # ç›®æ ‡å˜é‡
    y = df['volume_per_atom']
    print(f"\nğŸ“Š ç›®æ ‡å˜é‡ç»Ÿè®¡:")
    print(f"   æ ·æœ¬æ•°: {len(y)}")
    print(f"   å‡å€¼: {y.mean():.4f} Ã…Â³")
    print(f"   æ ‡å‡†å·®: {y.std():.4f} Ã…Â³")
    
    # åˆ›å»ºå¹³è¡¡çš„æ¨¡å‹
    print("\nğŸ”§ åˆ›å»ºå¹³è¡¡æ¨¡å‹...")
    model = Pipeline([
        ('scaler', StandardScaler()),
        ('xgb', xgb.XGBRegressor(
            n_estimators=600,
            max_depth=8,
            learning_rate=0.1,
            reg_lambda=0.1,
            reg_alpha=0.05,
            colsample_bytree=0.7,
            subsample=0.8,
            tree_method='hist',
            device='cpu',
            random_state=42,
            n_jobs=-1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        ))
    ])
    
    # 5-foldäº¤å‰éªŒè¯
    print(f"\nğŸ“Š è¿›è¡Œ 5-fold äº¤å‰éªŒè¯...")
    print("   è¿™å¯èƒ½éœ€è¦5-10åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    try:
        y_pred = cross_val_predict(model, X, y, cv=5, n_jobs=1, verbose=1)
        
        # è®¡ç®—æŒ‡æ ‡
        mae = mean_absolute_error(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        r2 = r2_score(y, y_pred)
        
        print(f"\nğŸ“ˆ Volume per atom (Ã…Â³) - è¯„ä¼°æŒ‡æ ‡:")
        print(f"   MAE:  {mae:.4f}")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   RÂ²:   {r2:.4f}")
        
        # è¯„ä¼°æ€§èƒ½
        if r2 >= 0.80:
            print("\nâœ… ä¼˜ç§€ï¼RÂ² â‰¥ 0.80")
        elif r2 >= 0.70:
            print("\nâœ“ è‰¯å¥½ï¼RÂ² â‰¥ 0.70")
        elif r2 >= 0.60:
            print("\nâ–³ ä¸­ç­‰ã€‚RÂ² â‰¥ 0.60")
        else:
            print(f"\nâš ï¸  RÂ²è¾ƒä½: {r2:.4f}")
        
        # åœ¨å…¨æ•°æ®ä¸Šè®­ç»ƒ
        print("\nğŸ¯ åœ¨å…¨æ•°æ®é›†ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
        model.fit(X, y)
        
        # ä¿å­˜æ¨¡å‹
        output_dir = Path('models/proxy_models')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        model_path = output_dir / 'lattice_model.pkl'
        joblib.dump(model, model_path)
        print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜ç‰¹å¾åç§°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
        feature_path = output_dir / 'feature_names.pkl'
        if not feature_path.exists():
            joblib.dump(list(valid_features), feature_path)
            print(f"âœ… ç‰¹å¾åç§°å·²ä¿å­˜: {feature_path}")
        
        # ä¿å­˜æŒ‡æ ‡
        metrics = {'mae': mae, 'rmse': rmse, 'r2': r2, 'target_name': 'Volume per atom (Ã…Â³)'}
        metrics_path = output_dir / 'lattice_metrics.pkl'
        joblib.dump(metrics, metrics_path)
        print(f"âœ… è¯„ä¼°æŒ‡æ ‡å·²ä¿å­˜: {metrics_path}")
        
        print("\n" + "=" * 80)
        print("âœ… æ¨¡å‹Bï¼ˆå¹³è¡¡ç‰ˆï¼‰è®­ç»ƒå®Œæˆï¼")
        print("=" * 80)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
