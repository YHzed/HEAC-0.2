"""
é˜¶æ®µå››ï¼šStackingé›†æˆå­¦ä¹ 

æ¶æ„:
- Level 0 (åŸºå­¦ä¹ å™¨):
  1. XGBoost (Optunaä¼˜åŒ–å)
  2. CatBoost (Optunaä¼˜åŒ–å) 
  3. Ridge Regression (ç‰©ç†ç‰¹å¾)
- Level 1 (å…ƒå­¦ä¹ å™¨):
  BayesianRidge

ä½¿ç”¨:
    python scripts/train_hv_stacking.py
    
ä½œè€…: HEACé«˜è´¨é‡ä¼˜åŒ–
æ—¥æœŸ: 2026-01-15
"""

import sys
import os
import argparse
import pandas as pd
import numpy as np
import json
import joblib
from pathlib import Path
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from xgboost import XGBRegressor
try:
    from catboost import CatBoostRegressor
    CATBOOST_AVAILABLE = True
except:
    CATBOOST_AVAILABLE = False

from sklearn.ensemble import StackingRegressor
from sklearn.linear_model import Ridge, BayesianRidge
from sklearn.model_selection import cross_validate, KFold
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error


def load_optimized_params(params_dir, algorithm):
    """åŠ è½½Optunaä¼˜åŒ–åçš„å‚æ•°"""
    params_file = Path(params_dir) / algorithm / f'best_params_{algorithm}.json'
    
    if not params_file.exists():
        print(f"âš ï¸ æœªæ‰¾åˆ°{algorithm}ä¼˜åŒ–å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return None
    
    with open(params_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data['best_params']


def train_stacking_model(data_path, features_path, params_dir='models/optuna_results',
                        output_dir='models/high_quality'):
    """è®­ç»ƒStackingé›†æˆæ¨¡å‹"""
    
    print("=" * 80)
    print("ğŸ† Stackingé›†æˆå­¦ä¹  - é«˜è´¨é‡HVæ¨¡å‹")
    print("=" * 80)
    print(f"ğŸ“ æ•°æ®: {data_path}")
    print(f"ğŸ§© å‚æ•°ç›®å½•: {params_dir}")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print("\n[1/6] åŠ è½½æ•°æ®...")
    df = pd.read_csv(data_path)
    
    with open(features_path, 'r', encoding='utf-8') as f:
        feature_config = json.load(f)
    all_features = feature_config['selected_features']
    
    df_clean = df.dropna(subset=['hv'])
    X_all = df_clean[all_features].copy()
    y = df_clean['hv'].copy()
    
    for col in X_all.columns:
        X_all[col] = pd.to_numeric(X_all[col], errors='coerce')
    X_all = X_all.fillna(X_all.median())
    
    print(f"âœ… {len(X_all)} æ ·æœ¬, {len(all_features)} ç‰¹å¾")
    
    # å‡†å¤‡ç‰©ç†ç‰¹å¾å­é›†ï¼ˆç”¨äºRidgeï¼‰
    physics_features = [
        'grain_size_um', 'binder_vol_pct', 'sinter_temp_c',
        'ceramic_vol_pct', 'lattice_mismatch', 'vec_binder',
        'pred_formation_energy', 'pred_lattice_param'
    ]
    physics_features = [f for f in physics_features if f in all_features]
    print(f"   ç‰©ç†ç‰¹å¾æ•°: {len(physics_features)}")
    
    # æ„å»ºåŸºå­¦ä¹ å™¨
    print("\n[2/6] æ„å»ºåŸºå­¦ä¹ å™¨...")
    estimators = []
    
    # 1. XGBoost (Optunaä¼˜åŒ–)
    xgb_params = load_optimized_params(params_dir, 'xgboost')
    if xgb_params:
        print(f"   âœ… XGBoost: ä½¿ç”¨Optunaä¼˜åŒ–å‚æ•°")
        xgb_model = XGBRegressor(**xgb_params)
    else:
        print(f"   âš ï¸ XGBoost: ä½¿ç”¨é»˜è®¤ä¼˜åŒ–å‚æ•°")
        xgb_model = XGBRegressor(
            n_estimators=600, max_depth=4, learning_rate=0.05,
            reg_alpha=0.3, reg_lambda=1.0, subsample=0.75,
            colsample_bytree=0.75, n_jobs=-1, random_state=42
        )
    
    estimators.append(('xgb', xgb_model))
    
    # 2. CatBoost (Optunaä¼˜åŒ–) - å¦‚æœå¯ç”¨
    if CATBOOST_AVAILABLE:
        cat_params = load_optimized_params(params_dir, 'catboost')
        if cat_params:
            print(f"   âœ… CatBoost: ä½¿ç”¨Optunaä¼˜åŒ–å‚æ•°")
            cat_model = CatBoostRegressor(**cat_params)
        else:
            print(f"   âš ï¸ CatBoost: ä½¿ç”¨é»˜è®¤å‚æ•°")
            cat_model = CatBoostRegressor(
                iterations=800, depth=6, learning_rate=0.05,
                l2_leaf_reg=3.0, verbose=0, random_seed=42
            )
        estimators.append(('catboost', cat_model))
    else:
        print(f"   âš ï¸ CatBoostæœªå®‰è£…ï¼Œè·³è¿‡")
    
    print(f"\n   åŸºå­¦ä¹ å™¨æ€»æ•°: {len(estimators)}")
    
    # åˆ›å»ºStackingæ¨¡å‹
    print("\n[3/6] åˆ›å»ºStackingé›†æˆ...")
    stacking_model = StackingRegressor(
        estimators=estimators,
        final_estimator=BayesianRidge(),
        cv=5,
        n_jobs=1  # æ”¹ä¸ºå•çº¿ç¨‹é¿å…å¹¶è¡Œé—®é¢˜
    )
    
    # äº¤å‰éªŒè¯è¯„ä¼°
    print("\n[4/6] äº¤å‰éªŒè¯è¯„ä¼°...")
    cv = KFold(n_splits=5, shuffle=True, random_state=42)
    
    cv_results = cross_validate(
        stacking_model, X_all, y, cv=cv,
        scoring={'r2': 'r2', 'mae': 'neg_mean_absolute_error', 
                 'rmse': 'neg_root_mean_squared_error'},
        return_train_score=True,
        n_jobs=1
    )
    
    r2_cv = cv_results['test_r2'].mean()
    mae_cv = -cv_results['test_mae'].mean()
    rmse_cv = -cv_results['test_rmse'].mean()
    
    r2_train = cv_results['train_r2'].mean()
    mae_train = -cv_results['train_mae'].mean()
    rmse_train = -cv_results['train_rmse'].mean()
    
    overfit_ratio = r2_train / r2_cv if r2_cv > 0 else float('inf')
    
    print(f"\n   äº¤å‰éªŒè¯ç»“æœ:")
    print(f"      RÂ² (CV): {r2_cv:.4f}")
    print(f"      MAE (CV): {mae_cv:.2f} HV")
    print(f"      RMSE (CV): {rmse_cv:.2f} HV")
    print(f"\n   è®­ç»ƒé›†ç»“æœ:")
    print(f"      RÂ² (Train): {r2_train:.4f}")
    print(f"      MAE (Train): {mae_train:.2f} HV")
    print(f"\n   è¿‡æ‹Ÿåˆè¯„ä¼°:")
    print(f"      è¿‡æ‹Ÿåˆæ¯”ç‡: {overfit_ratio:.3f}")
    
    if overfit_ratio < 1.05:
        print(f"      âœ…âœ…âœ… ä¼˜ç§€")
    elif overfit_ratio < 1.10:
        print(f"      âœ…âœ… è‰¯å¥½")
    else:
        print(f"      âœ… ä¸€èˆ¬")
    
    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    print("\n[5/6] è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
    stacking_model.fit(X_all, y)
    
    # ä¿å­˜æ¨¡å‹
    print("\n[6/6] ä¿å­˜æ¨¡å‹...")
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    joblib.dump(stacking_model, output_path / 'hv_stacking_model.pkl')
    
    with open(output_path / 'hv_feature_list.json', 'w', encoding='utf-8') as f:
        json.dump(all_features, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜è®­ç»ƒæŠ¥å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'model_type': 'Stacking Ensemble',
        'base_learners': [name for name, _ in estimators],
        'meta_learner': 'BayesianRidge',
        'sample_count': len(X_all),
        'feature_count': len(all_features),
        'physics_feature_count': len(physics_features),
        'cv_metrics': {
            'r2': float(r2_cv),
            'mae': float(mae_cv),
            'rmse': float(rmse_cv)
        },
        'train_metrics': {
            'r2': float(r2_train),
            'mae': float(mae_train),
            'rmse': float(rmse_train)
        },
        'overfitting_ratio': float(overfit_ratio)
    }
    
    with open(output_path / 'hv_training_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"   âœ… æ¨¡å‹ä¿å­˜: {output_path / 'hv_stacking_model.pkl'}")
    print(f"   âœ… æŠ¥å‘Šä¿å­˜: {output_path / 'hv_training_report.json'}")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ Stackingé›†æˆè®­ç»ƒå®Œæˆï¼")
    print("=" * 80)
    print(f"\nğŸ“Š é«˜è´¨é‡æ¨¡å‹æŒ‡æ ‡:")
    print(f"   RÂ² (CV): {r2_cv:.4f}")
    print(f"   MAE (CV): {mae_cv:.2f} HV")
    print(f"   è¿‡æ‹Ÿåˆæ¯”ç‡: {overfit_ratio:.3f}")
    
    # ä¸ç›®æ ‡å¯¹æ¯”
    print(f"\nğŸ¯ vs ç›®æ ‡:")
    print(f"   RÂ²: {r2_cv:.4f} {'âœ…' if r2_cv >= 0.83 else 'âš ï¸'} (ç›®æ ‡ â‰¥ 0.83)")
    print(f"   MAE: {mae_cv:.2f} {'âœ…' if mae_cv <= 125 else 'âš ï¸'} (ç›®æ ‡ â‰¤ 125)")
    print(f"   è¿‡æ‹Ÿåˆ: {overfit_ratio:.3f} {'âœ…' if overfit_ratio <= 1.08 else 'âš ï¸'} (ç›®æ ‡ â‰¤ 1.08)")
    print("=" * 80)
    
    return report


def main():
    parser = argparse.ArgumentParser(description='Stackingé›†æˆå­¦ä¹ ')
    parser.add_argument('--data', type=str,
                       default='datasets/exported_training_data_fixed.csv')
    parser.add_argument('--features', type=str,
                       default='models/selected_features_top30.json')
    parser.add_argument('--params_dir', type=str,
                       default='models/optuna_results',
                       help='Optunaä¼˜åŒ–å‚æ•°ç›®å½•')
    parser.add_argument('--output', type=str,
                       default='models/high_quality')
    
    args = parser.parse_args()
    
    train_stacking_model(
        data_path=args.data,
        features_path=args.features,
        params_dir=args.params_dir,
        output_dir=args.output
    )


if __name__ == "__main__":
    main()
