"""
ä¿®å¤ç‰ˆæ¨¡å‹Cè®­ç»ƒè„šæœ¬ - ç£çŸ©é¢„æµ‹å™¨

å¤„ç†magmomåˆ—çš„å‘é‡æ ¼å¼ï¼Œæå–æ€»ç£çŸ©

ä½œè€…: HEACé¡¹ç›®ç»„
"""

import sys
from pathlib import Path
import numpy as np

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ç›´æ¥ä½¿ç”¨sklearnå’Œxgboost
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb
import pandas as pd
import joblib

def parse_magmom(magmom_str):
    """
    è§£æmagmomå­—ç¬¦ä¸²ï¼Œæå–æ€»ç£çŸ©
    
    magmomå¯èƒ½æ˜¯ï¼š
    - å•ä¸ªæ•°å€¼: "0.025"
    - å‘é‡: "-0.025 0.030"  
    - è®¡ç®—æ€»ç£çŸ©ï¼ˆæ¨¡é•¿ï¼‰
    """
    if pd.isna(magmom_str):
        return np.nan
    
    try:
        # å°è¯•ç›´æ¥è½¬æ¢ä¸ºfloat
        return float(magmom_str)
    except (ValueError, TypeError):
        try:
            # å¦‚æœæ˜¯å‘é‡ï¼Œè®¡ç®—æ€»ç£çŸ©ï¼ˆç»å¯¹å€¼ä¹‹å’Œï¼‰
            values = [float(x) for x in str(magmom_str).split()]
            return np.abs(values).sum() if len(values) > 0 else np.nan
        except:
            return np.nan

def main():
    print("=" * 80)
    print("ğŸ¯ è®­ç»ƒæ¨¡å‹Cï¼ˆä¿®å¤ç‰ˆï¼‰: ç£çŸ©é¢„æµ‹å™¨")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½Zenodoæ•°æ®é›†...")
    data_path = 'training data/zenodo/structure_featurized.dat_all.csv'
    df = pd.read_csv(data_path, index_col=0)
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
    
    # å‡†å¤‡ç‰¹å¾
    print("\nğŸ”§ å‡†å¤‡ç‰¹å¾çŸ©é˜µ...")
    nfeatures = 273
    feature_names = df.columns[-nfeatures:]
    X_all = df[feature_names]
    
    # ç§»é™¤é›¶æ–¹å·®ç‰¹å¾
    variance = X_all.var()
    valid_features = variance[variance != 0].index
    X = X_all[valid_features]
    print(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆ: {len(valid_features)} ä¸ªæœ‰æ•ˆç‰¹å¾")
    
    # å¤„ç†ç£çŸ©æ•°æ®
    print("\nğŸ”§ å¤„ç†ç£çŸ©æ•°æ®...")
    print(f"   åŸå§‹magmomç±»å‹: {df['magmom'].dtype}")
    
    # è§£æmagmom
    magmom_parsed = df['magmom'].apply(parse_magmom)
    
    # ç§»é™¤NaNå€¼
    valid_mask = ~magmom_parsed.isna()
    X_clean = X[valid_mask]
    y_clean = magmom_parsed[valid_mask]
    
    print(f"   æœ‰æ•ˆæ ·æœ¬æ•°: {len(y_clean)} / {len(df)} ({len(y_clean)/len(df)*100:.1f}%)")
    print(f"\nğŸ“Š ç£çŸ©ç»Ÿè®¡:")
    print(f"   å‡å€¼: {y_clean.mean():.4f} Î¼B")
    print(f"   æ ‡å‡†å·®: {y_clean.std():.4f} Î¼B")
    print(f"   èŒƒå›´: [{y_clean.min():.4f}, {y_clean.max():.4f}] Î¼B")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ”§ åˆ›å»ºXGBoostæ¨¡å‹...")
    model = Pipeline([
        ('scaler', StandardScaler()),
        ('xgb', xgb.XGBRegressor(
            n_estimators=300,  # ç£çŸ©å¯èƒ½æ›´éš¾é¢„æµ‹ï¼Œä½¿ç”¨è¾ƒå°‘çš„æ ‘
            max_depth=6,
            learning_rate=0.2,
            reg_lambda=0.01,
            reg_alpha=0.1,
            colsample_bytree=0.5,
            tree_method='hist',
            device='cpu',
            random_state=42,
            n_jobs=-1
        ))
    ])
    
    # 5-foldäº¤å‰éªŒè¯
    print(f"\nğŸ“Š è¿›è¡Œ 5-fold äº¤å‰éªŒè¯...")
    
    try:
        y_pred = cross_val_predict(model, X_clean, y_clean, cv=5, n_jobs=1, verbose=1)
        
        # è®¡ç®—æŒ‡æ ‡
        mae = mean_absolute_error(y_clean, y_pred)
        rmse = np.sqrt(mean_squared_error(y_clean, y_pred))
        r2 = r2_score(y_clean, y_pred)
        mad = np.mean(np.abs(y_clean - np.mean(y_clean)))
        
        print(f"\nğŸ“ˆ Magnetic Moment (Î¼B) - è¯„ä¼°æŒ‡æ ‡:")
        print(f"   MAE:  {mae:.4f}")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   RÂ²:   {r2:.4f}")
        print(f"   MAD:  {mad:.4f}")
        
        # è¯„ä¼°æ€§èƒ½
        if r2 >= 0.70:
            print("\nâœ… ä¼˜ç§€ï¼RÂ² â‰¥ 0.70ï¼ˆç£çŸ©é¢„æµ‹é€šå¸¸è¾ƒéš¾ï¼‰")
        elif r2 >= 0.50:
            print("\nâœ“ è‰¯å¥½ï¼RÂ² â‰¥ 0.50")
        elif r2 >= 0.30:
            print("\nâ–³ ä¸­ç­‰ã€‚RÂ² â‰¥ 0.30")
        else:
            print(f"\nâš ï¸  RÂ²è¾ƒä½: {r2:.4f}")
            print("   ç£çŸ©é¢„æµ‹æ˜¯æŒ‘æˆ˜æ€§ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦æ›´å¤šç‰¹å¾å·¥ç¨‹")
        
        # åœ¨å…¨æ•°æ®ä¸Šè®­ç»ƒ
        print("\nğŸ¯ åœ¨å…¨æ•°æ®é›†ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
        model.fit(X_clean, y_clean)
        
        # ä¿å­˜æ¨¡å‹
        output_dir = Path('models/proxy_models')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        model_path = output_dir / 'magnetic_moment_model.pkl'
        joblib.dump(model, model_path)
        print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜ç‰¹å¾åç§°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
        feature_path = output_dir / 'feature_names.pkl'
        if not feature_path.exists():
            joblib.dump(list(valid_features), feature_path)
            print(f"âœ… ç‰¹å¾åç§°å·²ä¿å­˜: {feature_path}")
        
        # ä¿å­˜æŒ‡æ ‡
        metrics = {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'mad': mad,
            'target_name': 'Magnetic Moment (Î¼B)',
            'valid_samples': len(y_clean),
            'total_samples': len(df)
        }
        metrics_path = output_dir / 'magnetic_moment_metrics.pkl'
        joblib.dump(metrics, metrics_path)
        print(f"âœ… è¯„ä¼°æŒ‡æ ‡å·²ä¿å­˜: {metrics_path}")
        
        print("\n" + "=" * 80)
        print("âœ… æ¨¡å‹Cè®­ç»ƒå®Œæˆï¼")
        print("=" * 80)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
