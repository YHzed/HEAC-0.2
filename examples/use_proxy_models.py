"""
è¾…åŠ©æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„è¾…åŠ©æ¨¡å‹ä¸ºå®éªŒæ•°æ®æ³¨å…¥ç‰©ç†ç‰¹å¾

ä½œè€…: HEACé¡¹ç›®ç»„
æ—¥æœŸ: 2025-12-18
"""

import sys
from pathlib import Path
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.feature_injector import FeatureInjector
from core.data_standardizer import standardize_dataframe


def example_1_single_composition():
    """ç¤ºä¾‹1ï¼šä¸ºå•ä¸ªæˆåˆ†é¢„æµ‹ç‰©ç†å±æ€§"""
    print("=" * 80)
    print("ç¤ºä¾‹1ï¼šä¸ºå•ä¸ªæˆåˆ†é¢„æµ‹ç‰©ç†å±æ€§")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç‰¹å¾æ³¨å…¥å™¨
    injector = FeatureInjector(model_dir='models/proxy_models')
    
    # æµ‹è¯•æˆåˆ†
    test_compositions = [
        "AlCoCrFeNi",
        "CoCrNi",
        "TiZrNbTa",
    ]
    
    for comp_str in test_compositions:
        print(f"\nğŸ§ª æˆåˆ†: {comp_str}")
        print("-" * 40)
        
        # è§£ææˆåˆ†
        composition = injector.composition_parser.parse(comp_str)
        if composition is None:
            print("   âŒ è§£æå¤±è´¥")
            continue
        
        print(f"   è§£æç»“æœ: {composition}")
        
        # é¢„æµ‹å„é¡¹å±æ€§
        ef = injector.predict_formation_energy(composition)
        lattice = injector.predict_lattice_parameter(composition)
        magmom = injector.predict_magnetic_moment(composition)
        elastic = injector.predict_elastic_moduli(composition)
        pugh = injector.predict_pugh_ratio(composition, elastic['bulk'], elastic['shear'])
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\n   ğŸ“Š é¢„æµ‹ç»“æœ:")
        if ef is not None:
            print(f"      å½¢æˆèƒ½: {ef:.4f} eV/atom")
        if lattice is not None:
            mismatch = injector.calculate_lattice_mismatch(lattice)
            print(f"      æ™¶æ ¼å¸¸æ•°: {lattice:.4f} Ã…")
            print(f"      æ™¶æ ¼å¤±é… (vs WC): {mismatch:.2f} %")
        if magmom is not None:
            print(f"      ç£çŸ©: {magmom:.4f} Î¼B")
        if elastic['bulk'] is not None:
            print(f"      ä½“æ¨¡é‡: {elastic['bulk']:.2f} GPa")
        if elastic['shear'] is not None:
            print(f"      å‰ªåˆ‡æ¨¡é‡: {elastic['shear']:.2f} GPa")
        if pugh is not None:
            brittleness = injector.calculate_brittleness_index(pugh)
            material_type = "è„†æ€§" if pugh < 1.75 else "éŸ§æ€§"
            print(f"      Pughæ¯”: {pugh:.2f} ({material_type})")
            print(f"      è„†æ€§æŒ‡æ•°: {brittleness:.2f}")


def example_2_batch_dataframe():
    """ç¤ºä¾‹2ï¼šä¸ºDataFrameæ‰¹é‡æ³¨å…¥ç‰¹å¾"""
    print("\n\n" + "=" * 80)
    print("ç¤ºä¾‹2ï¼šä¸ºDataFrameæ‰¹é‡æ³¨å…¥ç‰¹å¾")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'Sample_ID': ['A1', 'A2', 'A3', 'A4'],
        'Binder_Comp': ['AlCoCrFeNi', 'CoCrNi', 'Co80Ni20', 'Fe50Co50'],
        'WC_Content': [90, 85, 88, 92],
        'Sinter_Temp': [1400, 1450, 1420, 1380],
        'Grain_Size': [1.0, 1.5, 1.2, 0.8],
        'Hardness': [1500, 1600, 1550, 1480]
    })
    
    print(f"\nğŸ“Š åŸå§‹æ•°æ® ({test_data.shape}):")
    print(test_data.to_string(index=False))
    
    # æ•°æ®æ ‡å‡†åŒ–
    print(f"\nğŸ”§ æ­¥éª¤1: æ•°æ®æ ‡å‡†åŒ–...")
    test_data_std = standardize_dataframe(test_data, 
                                          merge_duplicates=True,
                                          validate_types=True)
    
    # ç‰¹å¾æ³¨å…¥
    print(f"\nğŸ’‰ æ­¥éª¤2: ç‰¹å¾æ³¨å…¥...")
    injector = FeatureInjector(model_dir='models/proxy_models')
    
    try:
        test_data_enhanced = injector.inject_features(
            test_data_std,
            comp_col='binder_composition',  # æ ‡å‡†åŒ–åçš„åˆ—å
            verbose=True
        )
        
        # æ˜¾ç¤ºå¢å¼ºåçš„æ•°æ®
        print(f"\nâœ¨ å¢å¼ºåçš„æ•°æ® ({test_data_enhanced.shape}):")
        
        # åªæ˜¾ç¤ºæ–°å¢çš„ç‰¹å¾åˆ—
        new_feature_cols = [
            'pred_formation_energy',
            'lattice_mismatch_wc',
            'pred_magnetic_moment',
            'pred_bulk_modulus',
            'pred_pugh_ratio'
        ]
        
        available_cols = [col for col in new_feature_cols if col in test_data_enhanced.columns]
        if available_cols:
            print(test_data_enhanced[['sample_id'] + available_cols].to_string(index=False))
        
        # ä¿å­˜ç»“æœ
        output_file = "datasets/test_enhanced_data.csv"
        test_data_enhanced.to_csv(output_file, index=False)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except RuntimeError as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("   è¯·å…ˆè®­ç»ƒæ¨¡å‹: python scripts/train_proxy_models.py")


def example_3_real_data():
    """ç¤ºä¾‹3ï¼šå¤„ç†å®é™…çš„å®éªŒæ•°æ®"""
    print("\n\n" + "=" * 80)
    print("ç¤ºä¾‹3ï¼šå¤„ç†å®é™…çš„å®éªŒæ•°æ®")
    print("=" * 80)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å®é™…æ•°æ®
    data_file = "datasets/hea_processed.csv"
    if not Path(data_file).exists():
        print(f"\nâš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        print("   è¯·å…ˆä½¿ç”¨Process_Agentå¤„ç†åŸå§‹æ•°æ®")
        return
    
    # åŠ è½½æ•°æ®
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®: {data_file}")
    df = pd.read_csv(data_file)
    print(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
    
    # æ ‡å‡†åŒ–
    print(f"\nğŸ”§ æ•°æ®æ ‡å‡†åŒ–...")
    df_std = standardize_dataframe(df)
    
    # ç‰¹å¾æ³¨å…¥
    print(f"\nğŸ’‰ ç‰¹å¾æ³¨å…¥...")
    injector = FeatureInjector(model_dir='models/proxy_models')
    
    try:
        df_enhanced = injector.inject_features(df_std, comp_col='binder_composition')
        
        # ä¿å­˜
        output_file = "datasets/hea_enhanced_with_proxy.csv"
        df_enhanced.to_csv(output_file, index=False)
        print(f"\nâœ… å¢å¼ºæ•°æ®å·²ä¿å­˜: {output_file}")
        print(f"   æœ€ç»ˆå½¢çŠ¶: {df_enhanced.shape}")
        
        # æ˜¾ç¤ºç»Ÿè®¡
        print(f"\nğŸ“Š æ–°ç‰¹å¾ç»Ÿè®¡æ‘˜è¦:")
        proxy_features = [col for col in df_enhanced.columns if col.startswith('pred_')]
        if proxy_features:
            print(df_enhanced[proxy_features].describe().to_string())
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ è¾…åŠ©æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 80)
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    model_dir = Path('models/proxy_models')
    if not model_dir.exists() or not list(model_dir.glob('*.pkl')):
        print("\nâš ï¸  æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
        print("   è¯·å…ˆè®­ç»ƒæ¨¡å‹: python scripts/train_proxy_models.py")
        print("\n   æˆ–è€…æŸ¥çœ‹è®­ç»ƒçŠ¶æ€: python scripts/check_proxy_models.py")
        return
    
    # è¿è¡Œç¤ºä¾‹
    try:
        example_1_single_composition()
        example_2_batch_dataframe()
        # example_3_real_data()  # å–æ¶ˆæ³¨é‡Šä»¥å¤„ç†å®é™…æ•°æ®
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 80)
    print("âœ… ç¤ºä¾‹æ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
